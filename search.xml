<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[队列]]></title>
    <url>%2F2020%2F06%2F11%2F%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[数组模拟队列(单向) 队列三个要素, head,指向队列头; tail, 指向队列尾; maxCap, 队列总容量. 队列初始化的时候, head和tail都指向-1位置. 对于head而言, 指向的位置为弹出的元素. 在弹出的时候,head先+1, 再弹出head此时指向的元素. 对于tail而言, 指向的位置为队尾. 在压入元素的时候, tail先+1, 再放入元素. 当head == tail的时候, 说明队列为空. 当tail == maxCap的时候, 说明队列已满. 数组单向队列, 压入元素的时候会占用一个位置,当占满后,即便弹出元素,也无法释放空间. 所有的弹出都是伪弹出, 因为随着head的移动, 当查看队列内容的时候, 只是查看head到tail区间的元素. go代码实现数组模拟单向队列12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package mainimport "fmt"type Queue struct &#123; head int tail int maxCap int array [4]int&#125;func (q *Queue) isFull() bool &#123; // q.tail为下标，队列最大容量需要 if q.tail == q.maxCap &#123; fmt.Println("队列已满") return false &#125; return true&#125;func (q *Queue) isEmpty() bool &#123; if q.head == q.tail &#123; fmt.Println("队列为空") return false &#125; return true&#125;func (q *Queue) pushQueue(value int) &#123; // 先判断队列是否满 true为不满 if q.isFull() &#123; q.tail += 1 q.array[q.tail] = value &#125;&#125;func (q *Queue) popQueue() &#123; // 先判断队列是否为空 true为不空 if q.isEmpty() &#123; q.head += 1 fmt.Println("弹出元素为") fmt.Println(q.array[q.head]) &#125;&#125;func (q *Queue) showQueue() &#123; // 获取从head+1到tail+1位切片, 所以需要从head+1号位进行遍历到tail的位置。 // 需要判断是否为空 if q.isEmpty() &#123; // 因为被head指向的元素是已经被视为弹出了,所以要从head的下一位开始算. tmpHead := q.head + 1 for i:=tmpHead; i&lt;=q.tail;i++ &#123; fmt.Println(q.array[i]) &#125; &#125; else &#123; fmt.Println("空队列") &#125;&#125;func main() &#123; Q := &amp;Queue&#123; head:-1, tail:-1, maxCap:4, &#125; Q.pushQueue(1) Q.pushQueue(2) Q.pushQueue(3) Q.pushQueue(3) Q.popQueue() Q.showQueue()&#125;]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[稀疏数组(go语言实现)]]></title>
    <url>%2F2020%2F06%2F08%2F%E7%A8%80%E7%96%8F%E6%95%B0%E7%BB%84(go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0)%2F</url>
    <content type="text"><![CDATA[稀疏数组使用场景当一个二维数组的大部分元素为0，或者为相同值时，可以使用稀疏数组来压缩保存该二维数组。 稀疏数组处理方法 稀疏数组一般n行，3列，第一列表示原先二维数组的行，第二列表示原先二维数组的列，第三列表示值。 稀疏数组的第一行，一般用来表示原先二维数组的总行数以及总列数，值可以定义一个原先二维数组中不可能产生的值，比如-1,0。 简单的例子 原二维数组看做棋盘，白子为1，黑子为2。 稀疏数组第一行表示了”棋盘大小”为7*7，值为0，该值只是用于甄别其他有效值。 稀疏数组第二行至第四行表示了”棋盘”内白子黑子的分布，顺序为从上到下，从左到右。 可以将行和列看为x轴和y轴。 二维数组矩阵用稀疏数组表示(go语言思路) 每一个棋子有三个属性，x轴坐标，y轴坐标，颜色。一个棋子的属性可以用结构体来表示。 稀疏数组由于存在长度不确定性，所以使用切片的方式来表示。 稀疏数组的第一个元素围棋盘布局。 go代码对二维数组压缩保存为稀疏数组123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package mainimport "fmt"func main() &#123; // 定义一个7*7的二维数组, 将黑子白子进行赋值. var chessMap [7][7]int chessMap[1][1] = 1 chessMap[2][2] = 2 chessMap[2][4] = 1 chessMap[5][3] = 2 // 打印原始数据 for _,v := range chessMap &#123; for _,v2 := range v &#123; fmt.Printf("%d\t",v2) &#125; fmt.Printf("\n") &#125; // 用稀疏数组表示 /* 每一个棋子都有三个属性 1. x轴位置 2. y轴位置 3. 棋子颜色 这三个属性可以使用结构体来表示 然后将结构体依次append进数组中, 就可以作为一个稀疏数组了. */ // 定义一个存放棋子属性的结构体 type chess struct &#123; axisX int axisY int value int &#125; // 定义一个存放棋子结构体的切片 var chessSparseMap []chess // chessSparseMap稀疏数组第一行定义x,y和value firstLine := chess&#123; axisX: 7, axisY: 7, value: 0, &#125; chessSparseMap = append(chessSparseMap, firstLine) // 对原始数据进行遍历, 然后将获取到有数值内容的值,存储到chess结构体中, 并且将该结构体append到chessSparseMap里面. for k,v := range chessMap &#123; for k2,v2 := range v &#123; if v2 != 0 &#123; tmpChess := chess&#123; axisX:k, axisY:k2, value:v2, &#125; chessSparseMap = append(chessSparseMap, tmpChess) &#125; &#125; &#125; fmt.Println("稀疏数组为") fmt.Println(chessSparseMap)&#125;output:0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 稀疏数组为[&#123;7 7 0&#125; &#123;1 1 1&#125; &#123;2 2 2&#125; &#123;2 4 1&#125; &#123;5 3 2&#125;] 稀疏数组还原为二维数组123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package mainimport ( "fmt" "os" "bufio" "io" "strings" "strconv")func main() &#123; // 定义单个棋子的属性, x, y, value type chess struct &#123; axisX int axisY int value int &#125; // 定义一个7*7数组 var chessMap [7][7]int // 读取sparseMap文件 file, err := os.Open("./learn-go/数据结构/1.稀疏数组/sparseMap") defer file.Close() if err != nil &#123; fmt.Println("打开异常") return &#125; reader := bufio.NewReader(file) for &#123; content, err := reader.ReadString('\n') if err != nil &#123; fmt.Println("内容读取完毕") break &#125; if err == io.EOF &#123; break &#125; contentSlice := strings.Split(content," ") axisX, err := strconv.Atoi(contentSlice[0]) if err != nil &#123; fmt.Println("axisX转换出错") return &#125; axisY, err := strconv.Atoi(contentSlice[1]) if err != nil &#123; fmt.Println("axisY转换出错") return &#125; // strings.Split(contentSlice[2], "\r\n")[0] value结尾存在\n, 通过Split方法去除\r\n value, err := strconv.Atoi(strings.Split(contentSlice[2], "\r\n")[0]) if err != nil &#123; fmt.Println("value转换出错",err) return &#125; if value != 0 &#123; // axisX为x轴, axisY为y轴, value为棋子, 1 白子, 2 黑子 chessMap[axisX][axisY] = value &#125; &#125; for _,v := range chessMap &#123; for _, v2 :=range v&#123; fmt.Printf("%d \t",v2) &#125; fmt.Println() &#125;&#125;output:0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 sparseMap文件内容 123457 7 01 1 12 2 22 4 15 3 2]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[原码反码补码以及位运算]]></title>
    <url>%2F2020%2F04%2F30%2F%E5%8E%9F%E7%A0%81%E5%8F%8D%E7%A0%81%E8%A1%A5%E7%A0%81%E4%BB%A5%E5%8F%8A%E4%BD%8D%E8%BF%90%E7%AE%97%2F</url>
    <content type="text"><![CDATA[原码、反码、补码无符号用原码 计算机的运算都用的补码 正数 原码， 反码，补码都相同 负数 反码等于原码符号位不变，其他取反。 补码等于反码+1 例子 2的原码为0000 0010, 因为是正数，所以反码、补码都相同为0000 0010。 -2的原码为1000 0010, 最高位1为符号位，1表示负数，0表示正数。所以其反码为1111 1101, 补码为反码+1, 则为1111 1110。 位运算 位运算使用的都是反码。 位运算如果存在负数，最后都需要还原为原码得到真值。 异或-2和2做异或-2补码为1111 1110，2补码为0000 0010， 两者异或得到1111 1100。 因为存在-2,负数，所以需要对结果-1，然后除了符号位进行取反操作，得到真正的值(原码)，即对1111 1100减1，得到1111 1011，然后除去符号位取反，得到1000 0100，该值为-4。 位移运算 右移运算，&gt;&gt; 低位溢出，符号位不变，并用符号位(正数0补，负数1补)补溢出的高位 左移运算，&lt;&lt; 符号位不变，不够部分用0来补 位移运算如果存在负数，最后都需要还原为原码得到真值。 11&gt;&gt;2 1的补码为0000 0001, 右移2位，符号位不变，得到0000 0000即为0 11&lt;&lt;2 左移两位，符号位不变，不够的部分0补，得到0000 0100即为4 1-2&gt;&gt;2 -2的补码为1111 1110,右移2位，符号不变，高位溢出，用符号位1来补，得到1111 1111，然后-1，除去符号位取反还原回原码，1000 0001即为-1. 1-2&lt;&lt;2 -2的补码为1111 1110,右移2位，符号不变，不够部分用0补，得到1111 1000，然后-1，除去符号位取反得到原码为1000 1000，即为-8。 有些东西迟早还是要还的。。。]]></content>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[css居中-垂直方向]]></title>
    <url>%2F2020%2F03%2F18%2Fcss%E5%B1%85%E4%B8%AD-%E5%9E%82%E7%9B%B4%E6%96%B9%E5%90%91%2F</url>
    <content type="text"><![CDATA[查看如何水平居中 垂直居中相对比较复杂 行级元素(inline inline-*类型)垂直居中单行情况 有时候看似居中了，其实是上下padding预留了相同的空间，所以中间的内容居中了。 See the Pen Centering text (kinda) with Padding by huangyisan (@huangyisan) on CodePen. 不用padding，则可以将line-height和height的值设置相等。该方法比较常用。 See the Pen Centering a line with line-height by huangyisan (@huangyisan) on CodePen. 多行情况 多行情况也可以用padding填充等量的上下空间。如果不采用这种方式，则可以使用如下模拟table或者直接table元素的方式。 文字放到table里面进行处理。 使用css，模拟其他元素为table，来达到类似table的效果，但如果用了后者，则需要给vertical-align: middle属性。 See the Pen Centering text (kinda) with Padding by huangyisan (@huangyisan) on CodePen. 如果不用table方法，可以使用flexbox的方法。将内容放到一个flex里面，然后采用column的排列方式，并且给justify-content: center;属性居中。并且父元素要有一个高度。 See the Pen Vertical Center Multi Lines of Text with Flexbox by huangyisan (@huangyisan) on CodePen. 如果上面table和flex方式都不使用，则可以使用一种叫做“ghost element”的技术。在容器内设置一个全高度的伪元素，且让文字内容垂直对齐。 See the Pen Ghost Centering Multi Line Text by huangyisan (@huangyisan) on CodePen. 块级元素垂直居中 待设定元素高度已知的情况下，可以使用绝对定位配合负margin-top的方式实现。这种方式，即便缩放父元素高度，子元素还是属于居中状态。 See the Pen Center Block with Fixed Height by huangyisan (@huangyisan) on CodePen. 待设定元素高度未知情况下，可以使用transform: translateY(-50%)来处理居中。这种方式，即便缩放子元素高度，也是能保持居中的。 See the Pen Center Block with Unknown Height by huangyisan (@huangyisan) on CodePen. 如果不考虑缩放的时候需要居中，则可以使用table或者用css来达到table的方式来实现。 See the Pen Center Block with Table Stretch by huangyisan (@huangyisan) on CodePen. 也可以用flex布局来实现，和行级元素垂直居中思想一致。 See the Pen Center Block with Unknown Height with Flexbox by huangyisan (@huangyisan) on CodePen. flex布局如果父元素不给justify-content: center属性，则可以在子元素上添加margin: auto来实现居中效果。 See the Pen Center Block with Unknown Height with Flexbox by huangyisan (@huangyisan) on CodePen. ref: https://css-tricks.com/centering-css-complete-guide/]]></content>
      <tags>
        <tag>css</tag>
        <tag>html</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[css居中-水平方向]]></title>
    <url>%2F2020%2F03%2F14%2Fcss%E5%B1%85%E4%B8%AD-%E6%B0%B4%E5%B9%B3%E6%96%B9%E5%90%91%2F</url>
    <content type="text"><![CDATA[查看如何垂直居中 行级元素(inline inline-*类型)水平居中 只需要将需要水平居中的行级元素包裹在父级块级元素内，对父级元素设置text-align: center;属性即可。 对inline, inline-block, inline-table, inline-flex等属性都适用。 See the Pen Centering Inline Elements by huangyisan (@huangyisan) on CodePen. 一个块级元素水平居中 给该块级元素width属性，并且设置margin-left和margin-right皆为auto即可。 如果不给width属性，则宽度填满父级元素空间。 See the Pen Centering Single Block Level Element by huangyisan (@huangyisan) on CodePen. 多个块级元素水平居中 方法一： 若干块级元素在同一行居中，可以给这些块级元素设定相同的display属性(但并不是每个display的属性都适合水平居中)，比如给定inline-block属性 See the Pen Centering Row of Blocks by huangyisan (@huangyisan) on CodePen. 方法二：也可以给这些块级元素采用flex布局，也就是给其父级元素添加display: flex;，然后再给justify-content: center; See the Pen Centering Row of Blocks by huangyisan (@huangyisan) on CodePen. ref: https://css-tricks.com/centering-css-complete-guide/]]></content>
      <tags>
        <tag>css</tag>
        <tag>html</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用正确的姿势动态修改小程序样式]]></title>
    <url>%2F2020%2F03%2F13%2F%E5%B0%8F%E7%A8%8B%E5%BA%8Fwxs%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[我的小程序菜单栏点击延迟很大 小程序是用uni-app写的，写完真机调试发现菜单栏点击的延迟相当厉害，几乎有一到两秒。 微信开发工具的模拟界面点击没有任何的延迟感。 点击菜单栏会使得当前被点击的内容添加额外的样式，字体color为红色，背景为灰色。 排查思路 使用微信开发工具的”Audits”进行体验评分，体验分挺高的，但我自己的体验还是很差啊。 翻阅网上资料，修改样式也就差不多那么几种方式，我也是这样写的，感觉没毛病呀。 最小化配置，删减了所有其他相关组件，就留下了一个菜单，关联的样式也全部删掉，真机测试，还是有延迟。 怀疑是自己手机的问题，于是我用了下饿了么的小程序，大受打击，同时也让朋友真机测了下，也说有延迟感觉。 难道是uni-app框架的锅？行吧，我用小程序原生代码写了个菜单，点击发现的确比uniapp流畅点，但还是没有饿了么小程序那个菜单来的顺滑。 wdnmd，网上搜来搜去，说卡的基本上是组件过多，图片过多导致，跟我这个不太一样。 就这么过去了将近3天，一直没有头绪。让我更加在意的是饿了么为什么能那么流畅？ uni-app原代码template部分代码12345&lt;block v-for=&apos;(item,index) in foodsInfo&apos; :key=&apos;item.category&apos;&gt; &lt;view class=&apos;side-left-item&apos; @click=&quot;itemClick(index)&quot; :class=&quot;&#123;active: index === currentIndex&#125;&quot;&gt; &lt;text&gt;&#123;&#123;item.category&#125;&#125;&lt;/text&gt; &lt;/view&gt;&lt;/block&gt; JS部分代码123456789data() &#123; return &#123; currentIndex: 0, &#125;&#125;,methods: &#123; itemClick(index) &#123; this.currentIndex = index &#125; 小程序原生代码视图层部分代码123&lt;block wx:for=&quot;&#123;&#123;leftData&#125;&#125;&quot; wx:for-item=&quot;lcai&quot; wx:key=&quot;index&quot;&gt;&lt;view bindtap=&quot;btnClick&quot; data-index=&quot;&#123;&#123;index&#125;&#125;&quot; class=&quot;inner &#123;&#123;currentIndex == index? &apos;active&apos; : &apos;&apos;&#125;&#125;&quot;&gt;&#123;&#123;lcai.name&#125;&#125;&lt;/view&gt;&lt;/block&gt; 逻辑层部分代码123456789101112Page(&#123; data: &#123; currentIndex: 0, &#125;, btnClick: function(e) &#123; var index = e.currentTarget.dataset.index; console.log(index) this.setData(&#123; currentIndex: index &#125;) &#125;,&#125;) 原代码的实现方式 跟网上说的基本上一致，绑定点击事件，通过判断当前元素的index和currentIndex是否相等，返回true或者false来动态添加active样式(color:red; background-color: gray;)。 看着没有任何的问题，在pc端也是这么写的。 直到我看到了这篇文章 植树节晚上洗完澡一直在考虑这个问题，没有头绪，谷歌搜了下通用类的小程序优化思路。看到了如下这篇文章，才恍然大悟。 https://zhuanlan.zhihu.com/p/82741561 为什么会慢？ 小程序的视图层(wxml)和逻辑层(js)是独立分开的。这样视图层不能运行js代码，逻辑层的js代码也不能修改视图层的dom 当数据更新以及事件系统只能靠线程间通讯，但跨线程通信的成本极高，一些频繁通讯的场景，触摸、滚动等。 一个点击行为，需要经过视图层、Native、逻辑层三者之间2个完整来回的通信，通信的耗时开销较大，用户的交互就会出现延时卡顿的情况。 for循环对数据格式修改，也会造成逻辑层和视图层频繁通讯。 wxs的出现 wxs是一种被限制了的js，他可以运行在视图层。换句话说wxs和视图层的交互不需要经过Native层。 他是不可以操作dom的，因为小程序的视图层和逻辑层的分开就是为了不想用js直接操作dom。 wxs无法直接修改业务数据，只能对当前组件的class和style处理，或者数据进行格式化。 如果要修改业务逻辑数据，则需要用callMethod方法。 wxs适合的场景 用户交互频繁、仅需改动组件样式（比如布局位置），无需改动数据内容的场景，比如侧滑菜单、索引列表、滚动渐变等 - 数据格式处理，比如文本、日期格式化，或者国际化。 修改后的uni-app代码template部分代码123456&lt;block v-for=&apos;(item,index) in foodsInfo&apos; :key=&apos;index&apos;&gt; &lt;!-- 绑定多个class的方式，用数组，变量不需要加&#123;&#123;&#125;&#125; 点击事件绑定wxs中export的clickwxs--&gt; &lt;view :data-index=&quot;index&quot; :class=&apos;[&quot;side-left-item&quot;, &quot;inner_&quot; + index]&apos; @click=&quot;clickwxs.tapName&quot;&gt; &lt;text&gt;&#123;&#123;item.category&#125;&#125;&lt;/text&gt; &lt;/view&gt;&lt;/block&gt; WXS部分代码1234567891011121314151617181920212223//该代码和上面template代码为同一个文件下。//命名为clickwxs&lt;script module="clickwxs" lang="wxs"&gt;function tapName(event, ins) &#123; console.log(event.currentTarget.dataset.index) console.log(JSON.stringify(event)) var owner = ins.selectAllComponents('.side-left-item') console.log(owner) // 移除样式 for (var i = 0; i &lt; owner.length; i++) &#123; owner[i].removeClass('active'); console.log('.inner' + i) &#125; var instance = ins.selectComponent('.inner_' + event.currentTarget.dataset.index) console.log(instance) // 添加active样式 instance.addClass('active') instance.getDataset()&#125;module.exports = &#123; tapName: tapName&#125;&lt;/script&gt; 修改后的微信小程序原生代码视图层代码1234567891011&lt;!--引入wxs--&gt;&lt;wxs module="wxs" src="./index.wxs"&gt;&lt;/wxs&gt;&lt;view class="container"&gt;&lt;view&gt;&lt;scroll-view scroll-y="true" class="scroll"&gt;&lt;block wx:for="&#123;&#123;leftData&#125;&#125;" wx:for-item="lcai" wx:key="index"&gt;&lt;view bindtap="&#123;&#123;wxs.tapName&#125;&#125;" data-index="&#123;&#123;index&#125;&#125;" class="inner inner_&#123;&#123;index&#125;&#125;"&gt;&#123;&#123;lcai.name&#125;&#125;&lt;/view&gt;&lt;/block&gt;&lt;/scroll-view&gt;&lt;/view&gt;&lt;/view&gt; wxs代码1234567891011121314151617function tapName(event, ownerInstance) &#123; // 获取所有class="inner"的组件 var owner = ownerInstance.selectAllComponents('.inner') console.log(owner) // 清除样式 for (var i = 0; i &lt; owner.length; i++) &#123; owner[i].removeClass('active'); console.log('.inner_' + i) &#125; var instance = ownerInstance.selectComponent('.inner_' + event.currentTarget.dataset.index) // 添加active样式 instance.addClass('active') instance.getDataset()&#125;module.exports = &#123; tapName: tapName&#125; 结果修改完后，无论是uni-app框架的小程序，还是小程序原生的写法，点击延迟感不再有。 两份代码github地址 https://github.com/huangyisan/fooods leftbuttom分支 https://github.com/huangyisan/ori-fooods refer https://zhuanlan.zhihu.com/p/82741561 https://developers.weixin.qq.com/miniprogram/dev/framework/view/interactive-animation.html https://www.cnblogs.com/murenziwei/p/11233505.html]]></content>
      <tags>
        <tag>小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初始化样式和子绝父相]]></title>
    <url>%2F2020%2F03%2F02%2F%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A0%B7%E5%BC%8F%E5%92%8C%E5%AD%90%E7%BB%9D%E7%88%B6%E7%9B%B8%2F</url>
    <content type="text"><![CDATA[遇到的一些问题 最近把前端重新温习了下，然后在写小程序，首页样式就难住了，中间区块，怎么都无法铺满空白区域。 当时想到用子绝父相来解决，但即便使用了，还是有问题。中间区块设定bottom: 88rpx无法和底端bar对齐。 排查结果 内容块无法准确拉伸位置到bottom: 88rpx，是因为父组件的高度有问题，这个父组件为最外层的组件.content，我当时给的高度是height: 100%。 然后因为.content是page根组件的子组件，所以height:100% 是继承page的高度，但page并没有设定高度，所以出现了问题。 思考如何给page设置一个合理的高度 因为用的是小程序，所以手机端有不同的高度，苹果6和苹果x高度就不一致，如果我设定一个固定高度，那么适配不同手机屏幕肯定会存在问题。 后来查阅了文档，vh这个属性表示视口高度，也就是当前屏幕可见范围的高度，100vh表示整个屏幕，不论这个屏幕是什么类型的手机。 其实只要给.content设置100vh即可。 配合子绝父相 让.content作为父元素，使用相对定位，设置position: relative。 再添加height: 100vh;属性。 白色区块内容作为子元素，让其绝对定位，设置position: absolute。 然后子元素使用top, bottom, left, right进行调整位置。 注意点 一开始初始化那会，要给最外层的先设定一个高度，如果是动态的话就给一个100vh的高度填满视口。 在父元素没有高度的时候，子元素使用height: 100%是没有效果的，即便是根组件使用，也是没有效果，这个和width: 100%不一样，不会撑开高度，具体原因浏览器根本就不计算内容的高度，除非内容超出了视窗范围(导致滚动条出现)。或者你给整个页面设置一个绝对高度。否则，浏览器就会简单的让内容往下堆砌，页面的高度根本就无需考虑。 最终代码 html代码 12345678&lt;template&gt; &lt;view class="content"&gt; &lt;c-swiper class='foods-wrapper'&gt;&lt;/c-swiper&gt; &lt;c-search&gt;&lt;/c-search&gt; &lt;c-foods-list&gt;&lt;/c-foods-list&gt; &lt;c-bottom-bar&gt;&lt;/c-bottom-bar&gt; &lt;/view&gt;&lt;/template&gt; content部分 12345678910.content &#123; display: flex; flex-direction: column; width: 100%; background-color: #007AFF; /* 视口高度100 */ height: 100vh; /* 子绝父相，有利于子元素定位 */ position: relative;&#125; foods-wrapper部分代码 123456789.foods-wrapper &#123; display: flex; flex-direction: row; position: absolute; background-color: #C03189; width: 100%; top: 350rpx; bottom: 88rpx;&#125; refer http://www.webhek.com/post/css-100-percent-height.html]]></content>
      <tags>
        <tag>css，小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JWT认证的实现]]></title>
    <url>%2F2020%2F02%2F29%2FJWT%E8%AE%A4%E8%AF%81%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[什么是JWT，以及原理网上有大把解释JWT认证原理的，直接看refer部分。 JWT认证 当用户登陆的时候，后端根据部分字段进行签名，然后将签名得到的数据返回给用户。 用户下一次请求数据的时候，在请求头的authentication字段携带token。 服务端收到token后进行解密，前两段用私钥签名的结果跟第三段对比，看是否一致，如果一致，则判定当前用户合法，反之则非法。 JWT的token为三段，前两段用base64编码，可以解开，第一段是描述认证方式和算法，第二段就是具体的一些信息，第三段为服务端私钥根据前两段内容进行的签名，也就是加密部分。 JWT后端部分代码 后端使用python写，求快，直接用的sanic库，以下为主要代码，只求结果正确。 主要逻辑： 登录认证通过，则后端根据username以及一些基本信息生成token，然后返回给前端 123456789101112...... token = jwt.encode(payload, 'today', headers=jwt_headers, algorithm='HS256').decode() # 若用户名和密码为admin， 则认为认证通过 if username == 'admin' and password == 'admin': return json(&#123;'code': 200, 'info': 'authSuccess','access_token': token, 'account_id': username&#125;) else: return json(&#123;'code': 401, 'info': 'authFaildd'&#125;)...... 其他但凡和后端存在数据交互的，则进行token的认证，将该方法作为装饰器。 12345678910111213141516171819202122232425def check(func): print('执行check') def wrapper(request): print('执行wrapper') jwt_headers = &#123; "alg": "HS256", "typ": "JWT" &#125; token = request.headers.get('authorization') if token: token = token.split(' ')[-1] try: payload = jwt.decode(token, 'today', audience='yisan.com', headers=jwt_headers, algorithms=['HS256']) if payload: return func(request) return json(&#123;'code': 401, 'info': 'checkFailed'&#125;) except Exception as e: print(e) return json(&#123;'code': 401, 'info': 'checkFailed'&#125;) # 具体要请求的接口数据 return json(&#123;'code': 405, 'info': '函数没有返回值'&#125;) return wrapper JWT前端部分代码 主要使用axios的响应拦截器，对返回json数据的code值进行判断。 主要逻辑 axios相应拦截器 123456789101112131415161718instance.interceptors.response.use(res =&gt; &#123; const code = res.data.code console.log(document.location) console.log(res) // 后端返回401, 且当前uri不是/login, 则跳转到login页面 if (code === 401 &amp;&amp; document.location.pathname !== '/login') &#123; console.log('登陆失败或失效') sessionStorage.removeItem('token') router.push('/login') return res.data // 后端返回401， 且当前uri是/login, 则不跳转，防止死循环 &#125; else if (code === 401 &amp;&amp; document.location.pathname === '/login') &#123; // console.log('不跳转了') // return false return res.data &#125; return res.data&#125;) /login页面，在created阶段，发送token验证请求，如果当前为登陆状态，则跳转至/homepage 123456789created() &#123; this.token = sessionStorage.getItem('token') tokenCheck(this.token).then(res =&gt; &#123; console.log(res) if (res.code === 200) &#123; this.$router.push('/homepage') &#125; &#125;)&#125; GitHub仓库地址 https://github.com/huangyisan/simulator_jwt_auth.git refer https://zhuanlan.zhihu.com/p/70275218 https://segmentfault.com/a/1190000010312468 https://jasonwatmore.com/post/2018/07/06/vue-vuex-jwt-authentication-tutorial-example https://juejin.im/post/5ce3e9146fb9a07eba2c1258]]></content>
      <tags>
        <tag>python3</tag>
        <tag>vue</tag>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编写自定义 django-admin 命令]]></title>
    <url>%2F2019%2F11%2F07%2F%E7%BC%96%E5%86%99%E8%87%AA%E5%AE%9A%E4%B9%89django_admin%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[我想在django中放一个脚本，然后循环执行他，该脚本会操作数据库，我懒得自己pymysql等方式写，就想用orm的方式，直接脚本中import models，但是呢，python xxxx执行后各种报错，说找不到环境变量，网上搜了下解决方案，也是差不多，但我就是没有调试出来。于是打算用django自带的方式执行命令。 目录结构 在app中创建/management/commands目录 在commands目录里面创建py脚本 例如我的app叫做gp_volume，则在这个路径下创建/management/commands，然后放了两个脚本，一个是page_manager.py，一个是test.py。 1234567891011.|-- admin.py|-- apps.py|-- __init__.py|-- management| `-- commands| |-- page_manager.py| |-- __pycache__| | |-- page_manager.cpython-36.pyc| | `-- test.cpython-36.pyc| `-- test.py 脚本编写 脚本代码需要封装在Command这个类里面，且继承BaseCommand类 对Command类的handle函数进行重写 拿个page_manager.py举例 12345678910111213from django.core.management.base import BaseCommand, CommandErrorfrom gp_volume.models import Code, Volume, Pageimport datetime# 编写Command类，并且继承BaseCommandclass Command(BaseCommand): # 重写handle函数 def handle(self, *args, **options): code_list = Code.objects.filter(status=&apos;o&apos;, date=str(datetime.date.today())) for code in code_list: print(code.code) 脚本执行 python3 manage.py ${script_name} 例如跑page_manager.py，无需脚本后缀名 1python3 manager page_manager 传参给脚本 定义add_arguments方法 使用options[‘key’]获取传入的参数 test.py例子 12345678910111213141516171819202122from django.core.management.base import BaseCommand, CommandErrorfrom gp_volume.models import Code, Volume, Pageimport datetimeclass Command(BaseCommand): def add_arguments(self, parser): # nargs=&apos;+&apos; 表示至少要有一个参数 parser.add_argument(&apos;code_id&apos;, nargs=&apos;+&apos;, type=str) parser.add_argument( &apos;--delete&apos;, # store_True表示参数如果不写，默认没有。 action=&apos;store_True&apos;, help=&apos;Delete poll instead of closing it&apos;, ) def handle(self, *args, **options): # 判断是否存在delete参数 if options[&apos;delete&apos;]: for code in options[&apos;code_id&apos;]: Code.objects.get(code=code).delete() else: print(&apos;no args&apos;) 执行命令 1python3 manage.py test --delete xxxxxxx refer https://docs.djangoproject.com/en/2.2/howto/custom-management-commands/]]></content>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django Model Relationship]]></title>
    <url>%2F2019%2F11%2F04%2FDjango_Model_Relationship%2F</url>
    <content type="text"><![CDATA[好久没写了，这次用阴阳师来举例子。 Django Model的三种Relationship 一对一 (关键词 OneToOneField) 一对多 (关键词 ForeignKey) 没有OneToManyField这种写法 多对多 (关键词 ManyToManyField) 代码和关系1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253from django.db import models# Create your models here.# 定义稀有度，五个等级，n r sr ssr spclass Rare(models.Model): N = &apos;n&apos; R = &apos;r&apos; SR = &apos;sr&apos; SSR = &apos;ssr&apos; SP = &apos;sp&apos; LEVEL_CHOICES = [ (N,&apos;N&apos;), (R,&apos;R&apos;), (SR,&apos;SR&apos;), (SSR,&apos;SSR&apos;), (SP,&apos;SP&apos;), ] # one to one relationship with formula level = models.CharField(max_length=4, choices=LEVEL_CHOICES,default=SSR,unique=True) def __str__(self): return self.level# 定义式神名称class Formula(models.Model): # 一对多定义 rare = models.ForeignKey(Rare, on_delete=models.CASCADE) name = models.CharField(max_length=10, unique=True, primary_key = True) def __str__(self): return self.name# 定义cp字段class Lover(models.Model): # 一对一定义 formula = models.OneToOneField(Formula, on_delete=models.SET_NULL,null=True) lover_name = models.CharField(max_length=10,unique=True) def __str__(self): return self.lover_name# 定义御魂套字段class Soul(models.Model): # 多对多定义 formula = models.ManyToManyField(Formula) # 御魂套名称 set = models.CharField(max_length=10,unique=True) def __str__(self): return self.set 式神和其cp为一对一关系，酒吞置于红叶，鲤鱼精至于河童。 稀有度和式神为一对多关系。 一个种稀有度能对应多个式神，但一个式神只能有一种稀有度。 御魂套和式神为多对多关系。一套御魂可以给多个式神使用，一个式神也可以使用多套御魂。 给数据库创建一些数据创建的方法 使用对象属性来创建 使用objects来创建 使用对象属性创建如果是创建自身的数据，则对象要调用save()，如果是创建关联性数据，则无需调用save() 123456创建了稀有度为n的数据&gt;&gt;&gt; from onmyoji_models.models import *&gt;&gt;&gt; n = Rare(level=&apos;n&apos;)&gt;&gt;&gt; n.save()&gt;&gt;&gt; Rare.objects.all()&lt;QuerySet [&lt;Rare: n&gt;]&gt; 使用objects来创建使用objects来创建无需调用save() 1234&gt;&gt;&gt; Rare.objects.create(level=&apos;sr&apos;)&lt;Rare: sr&gt;&gt;&gt;&gt; Rare.objects.all()&lt;QuerySet [&lt;Rare: n&gt;, &lt;Rare: sr&gt;]&gt; 我该把关键词写在哪里 OneToOneField，一对一的情况，随便写。 ForeignKey，一对多的情况，写在多的一方，一种稀有度对应多个式神，所以ForeignKey定义在式神上，也就是class Formula上。 ManyToManyField，多对多的情况，任意写。 建议将字段命名为关联class的小写，比如一对多，在class Formula需要定义一个ForeignKey字段和class Rare关联，则该字段名为’rare’。 1rare = models.ForeignKey(Rare, on_delete=models.CASCADE) 三种关系的例子和相互读取一对一用酒吞和红叶举例子。 先创建酒吞，因为Formula有个rare字段的是关联了class Rare，所以要先获取rare的instance对象，将对象赋值给rare，然后创建酒吞。 这边要注意的是，如果获取instance对象，则需要用到get()方法，倘若使用的是filter()，则获取的是一个query set对象，是不能够给rare赋值的。 123ssr = Rare.objects.get(level=&apos;ssr&apos;)Formula.objects.create(name=&apos;JiuTun&apos;,rare=ssr)&lt;Formula: JiuTun&gt; 接着在Lover中创建红叶。formula是个传入的对象，所以先get()获取到酒吞 123&gt;&gt;&gt; jiutun = Formula.objects.get(name=&apos;JiuTun&apos;)&gt;&gt;&gt; Lover.objects.create(lover_name=&apos;HongYe&apos;,formula=jiutun)&lt;Lover: HongYe&gt; 相互之间访问数据 Formula到Lover 对象属性方式，formula对象直接访问lover的lover_name字段 123&gt;&gt;&gt; jiutun = Formula.objects.get(name=&apos;JiuTun&apos;)&gt;&gt;&gt; jiutun.lover.lover_name&apos;HongYe&apos; objects的方式,传入的formula是instance对象 12345&gt;&gt;&gt; jiutun = Formula.objects.get(name=&apos;JiuTun&apos;)&gt;&gt;&gt; Lover.objects.get(formula=jiutun)&lt;Lover: HongYe&gt;&gt;&gt;&gt; Lover.objects.get(formula=jiutun).lover_name&apos;HongYe&apos; Lover到Formula 对象属性方式，访问formula的name字段 123&gt;&gt;&gt; hongye = Lover.objects.get(lover_name=&apos;HongYe&apos;)&gt;&gt;&gt; hongye.formula.name&apos;JiuTun&apos; objects的方式，传入的lover是instance对象 1234&gt;&gt;&gt; Formula.objects.get(lover=hongye)&lt;Formula: JiuTun&gt;&gt;&gt;&gt; Formula.objects.get(lover=hongye).name&apos;JiuTun&apos; 一对多通过对象属性的方式给给Formula添加鬼切式神。 123&gt;&gt;&gt; guiqie = Formula(name=&apos;GuiQie&apos;, rare=ssr)&lt;Formula: GuiQie&gt;&gt;&gt;&gt; guiqie.save() 此时数据库内有数据了，formula为Guiqie,其rare为ssr。 相互之间访问数据 从多(Formula)到一(Rare) 对象属性方式123&gt;&gt;&gt; formula = Formula.objects.get(name=&apos;GuiQie&apos;)&gt;&gt;&gt; formula.rare.level&apos;ssr&apos; objects方式,访问Rare的level字段1234&gt;&gt;&gt; Rare.objects.get(formula=formula)&lt;Rare: ssr&gt;&gt;&gt;&gt; Rare.objects.get(formula=formula).level&apos;ssr&apos; 从一(Rare)到多(Formula) 因为访问多，所以属性方法访问要用_set，objects对象访问则建议用filter()，因为get()遇到大于1个数据会报错。因为是访问的多，所以得到结果是query set类型，访问具体数据，需要迭代进行访问。 对象属性方式 12345678&gt;&gt;&gt; ssr = Rare.objects.get(level=&apos;ssr&apos;)&gt;&gt;&gt; ssr.formula_set.all()&lt;QuerySet [&lt;Formula: GuiQie&gt;, &lt;Formula: CiMuTongZi&gt;]&gt;&gt;&gt;&gt; for i in ssr.formula_set.all():... print(i)...GuiQieCiMuTongZi objects方式 1234567&gt;&gt;&gt; ssr = Rare.objects.get(level=&apos;ssr&apos;)&gt;&gt;&gt; formulas = Formula.objects.filter(rare=ssr)&gt;&gt;&gt; for i in formulas:... print(i)...GuiQieCiMuTongZi 多对多代码里，ManyToManyField定义在class Soul。 使用objects方式创建破势套和针女套 1234&gt;&gt;&gt; Soul.objects.create(set=&apos;PoShi&apos;)&lt;Soul: Soul object (1)&gt;&gt;&gt;&gt; Soul.objects.create(set=&apos;ZhenNv&apos;)&lt;Soul: Soul object (2)&gt; 指定Soul(御魂)关联给Formula(式神)，使用add的方式 12&gt;&gt;&gt; zhennv = Soul.objects.get(set=&apos;ZhenNv&apos;)&gt;&gt;&gt; zhennv.formula.add(guiqie) 指定Formula(式神)关联给Soul(御魂)，使用add的方式 12poshi = Soul.objects.get(set=&apos;PoShi&apos;)&gt;&gt;&gt; guiqie.soul_set.add(poshi) 将指定御魂(Soul)关联所有式神(Formula)，使用set()方法 123&gt;&gt;&gt; all = Formula.objects.all()&gt;&gt;&gt; poshi = Soul.objects.get(set=&apos;PoShi&apos;)&gt;&gt;&gt; poshi.formula.set(all) 将指定式神关联所有御魂，使用set()方法 123&gt;&gt;&gt; all = Soul.objects.all()&gt;&gt;&gt; Yi=Formula.objects.get(name=&apos;Yi&apos;)&gt;&gt;&gt; Yi.soul_set.set(all) 相互之间访问数据（好像不存在objects访问的方法，待考证） 通过式神(Formula)获取御魂(Soul, ManyToManyField),使用_set.value()方式 对象属性方式 12&gt;&gt;&gt; guiqie.soul_set.values()&lt;QuerySet [&#123;&apos;id&apos;: 1, &apos;set&apos;: &apos;ZhenNv&apos;&#125;]&gt; 通过御魂(Soul, ManyToManyField)查询式神(Formula) 对象属性方式12&gt;&gt;&gt; poshi.formula.values()&lt;QuerySet [&#123;&apos;rare_id&apos;: 4, &apos;name&apos;: &apos;GuiQie&apos;&#125;]&gt; refer https://imliyan.com/blogs/article/Django%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BE%8B/https://docs.djangoproject.com/en/2.2/ref/models/fields/#django.db.models.OneToOneFieldhttps://docs.djangoproject.com/en/2.2/ref/models/fields/#django.db.models.ForeignKeyhttps://docs.djangoproject.com/en/2.2/ref/models/fields/#django.db.models.ManyToManyFieldhttps://docs.djangoproject.com/en/2.2/topics/db/examples/many_to_many/]]></content>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速排序]]></title>
    <url>%2F2019%2F09%2F03%2F%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[快速排序 快速排序用到的是分治思想。 实现方法是，在序列中先确定一个比较值k，左边部分的值比k小，右边部分的值比k大，然后对左边和右边两部分继续获取各自的比较值k，依次递归，直到都排列完成，从而整个数列都变得有序。 退出条件是，左边增长的角标大于右边缩小的角标。 排序基本思路 给定一个数组，比如[3，6，1，7，2，4，8]。 先选定一个k，作为比较值，比如选取数组第一个数值，3。 从右边开始，同3比较，右边第一个数值8，因为8&gt;3,所以8不需要动，此时还是[3，6，1，7，2，4，8]。 接着比较倒数第二位4，4&gt;3，也不需要动，此时还是[3，6，1，7，2，4，8]。 接着倒数第三位2，2&lt;3，则将2放入3的位置，变成[2,6,1,7,2,4,8]，此时右边角标为4。 触发了右边的变换，所以这次开始从左边，2&lt;3，则不需要动，[2,6,1,7,2,4,8]。 左边继续走，第二个为6，6&gt;3，则需要变换[2,6,1,7,6,4,8]，此时左边角标为1 左边触发了交换，下面轮到右边，右边7，7&gt;3，不变，[2,6,1,7,6,4,8]。 右边继续，右边1，1&lt;3，则交换，变成[2,1,1,7,6,4,8]，此时右边角标为1。 轮到左边，左边继续，为1，依旧是[2,1,1,7,6,4,8]，此时左边角标为2。 继续轮到左边，此时左边发现自己角标大于右边角标，则停止，将k的值赋予当前左边角标，数组也就成了[2,1,3,7,6,4,8]。 之后出现左右两个子数组，继续递归，直到全部完成。 代码实现https://www.jianshu.com/p/2b2f1f79984e 123456789101112131415161718192021222324252627282930313233343536373839quicklist = [3,6,1,7,2,4,8]def quick_sort(arr): return q_sort(arr, 0, len(arr) - 1)def q_sort(arr, left, right): if left &lt; right: pos = get_pos(arr,left,right) # 递归左边排序，第一次left为0，pos-1的值为get_pos排序一次后的pos位置左移一位。 q_sort(arr,left,pos-1) # 递归右边排序，pos+1的值为get_pos排序一次后的pos位置右移一位。 q_sort(arr,pos+1,right) # 得到最终排序完的列表 return arrdef get_pos(arr,left,right): # 左边第一位作为pos值 pos = arr[left] # 判断左右位置角标是否相遇 while left &lt; right: while left &lt; right and arr[right] &gt;= pos: # 右边角标缩小 right -=1 # 将右边的换到左边 arr[left] = arr[right] while left &lt; right and arr[left] &lt;= pos: # 左边角标放大 left +=1 # 将左边的换到右边 arr[right] = arr[left] # 当左边和右边位置碰到的时候，让此时左边的位置成为pos值，因为pos值当时是被抠出来的。 arr[left] = pos # 获取此时的left位置 return leftprint(quick_sort(quicklist)) 总结快速排序之所比较快，因为相比冒泡排序，每次交换是跳跃式的。每次排序的时候设置一个基准点，将小于等于基准点的数全部放到基准点的左边，将大于等于基准点的数全部放到基准点的右边。这样在每次交换的时候就不会像冒泡排序一样每次只能在相邻的数之间进行交换，交换的距离就大的多了。因此总的比较和交换次数就少了，速度自然就提高了。当然在最坏的情况下，仍可能是相邻的两个数进行了交换。因此快速排序的最差时间复杂度和冒泡排序是一样的都是 O(N2)，它的平均时间复杂度为 O(NlogN)。 refer https://wiki.jikexueyuan.com/project/easy-learn-algorithm/fast-sort.htmlhttps://www.jianshu.com/p/2b2f1f79984e]]></content>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis主从复制(搬运)]]></title>
    <url>%2F2019%2F07%2F30%2FRedis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[如何使用主从复制建立复制主从复制的开启，完全是在从节点发起的；不需要我们在主节点做任何事情。 从节点开启主从复制，有3种方式 配置文件 在从服务器的配置文件中加入：slaveof \&lt;masterip> \&lt;masterport> 启动命令 redis-server启动命令后加入 –slaveof \&lt;masterip> \&lt;masterport> 客户端命令 Redis服务器启动后，直接通过客户端执行命令：slaveof \&lt;masterip> \&lt;masterport>，则该Redis实例成为从节点。 断开复制通过slaveof &lt;masterip&gt; &lt;masterport&gt;命令建立主从复制关系以后，可以通过slaveof no one断开。需要注意的是，从节点断开复制后，不会删除已有的数据，只是不再接受主节点新的数据变化。 主从复制的实现原理主从复制过程大体可以分为3个阶段 连接建立阶段 数据同步阶段 命令传播阶段 连接建立阶段该阶段的主要作用是在主从节点之间建立连接，为数据同步做好准备。 保存主节点信息 从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。 slaveof是异步命令，从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行。 建立socket连接 从节点每秒1次调用复制定时函数replicationCron()，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接 从节点：为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。 主节点：接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。 发送ping命令 从节点成为主节点的客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。 从节点发送ping命令后，可能出现3种情况： 返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。 超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。 返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。 身份验证 如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。 如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。 发送从节点端口信息 身份验证之后，从节点会向主节点发送其监听的端口号（前述例子中为6380），主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。 数据同步阶段 主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。具体执行的方式是：从节点向主节点发送psync命令（Redis2.8以前是sync命令），开始同步。 数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复制。 需要注意的是，在数据同步阶段之前，从节点是主节点的客户端，主节点不是从节点的客户端；而到了这一阶段及以后，主从节点互为客户端。原因在于：在此之前，主节点只需要响应从节点的请求即可，不需要主动发请求，而在数据同步阶段和后面的命令传播阶段，主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。 数据同步阶段–全量复制和部分复制 全量复制用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。Redis通过psync命令进行全量复制的过程如下： 从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行全量复制。 主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令。 主节点的bgsave执行完成后，将RDB文件发送给从节点；从节点首先清除自己的旧数据，然后载入接收的RDB文件，将数据库状态更新至主节点执行bgsave时的数据库状态。 主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态。 如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态。 部分复制用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制。部分复制的实现，依赖于三个重要的概念： 复制偏移量 主节点和从节点分别维护一个复制偏移量（offset），代表的是主节点向从节点传递的字节数；主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。 offset用于判断主从节点的数据库状态是否一致：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。 复制积压缓冲区 复制积压缓冲区是由主节点维护的、固定长度的、先进先出(FIFO)队列，默认大小1MB；当主节点开始有从节点时创建，其作用是备份主节点最近发送给从节点的数据。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。 在命令传播阶段，主节点除了将写命令发送给从节点，还会发送一份给复制积压缓冲区，作为写命令的备份；除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。 由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。 从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制： 如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制； 如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制。 服务器运行ID(runid) 每个Redis节点(无论主从)，在启动时都会自动生成一个随机ID(每次启动都不一样)，由40个随机的十六进制字符组成；runid用来唯一识别一个Redis节点。通过info Server命令，可以查看节点的runid。 主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点；主节点根据runid判断能否进行部分复制 如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)。 如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。 psync命令的执行psync命令的执行过程可以参见下图 首先，从节点根据当前状态，决定如何调用psync命令 如果从节点之前未执行过slaveof或最近执行了slaveof no one，则从节点发送命令为psync ? -1，向主节点请求全量复制。 如果从节点之前执行了slaveof，则发送命令为psync \&lt;runid> \&lt;offset>，其中runid为上次复制的主节点的runid，offset为上次复制截止时从节点保存的复制偏移量。 主节点根据收到的psync命令，及当前服务器状态，决定执行全量复制还是部分复制 如果主节点版本低于Redis2.8，则返回-ERR回复，此时从节点重新发送sync命令执行全量复制。 如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可。 如果主节点版本够新，但是runid与从节点发送的runid不同，或从节点发送的offset之后的数据已不在复制积压缓冲区中(在队列中被挤出了)，则回复+FULLRESYNC \&lt;runid> \&lt;offset>，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从节点保存这两个值，以备使用。 命令传播阶段 数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。 在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。 需要注意的是，命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。 repl-disable-tcp-nodelay no：该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小。 一般来说，只有当应用对Redis数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为yes；多数情况使用默认值no。 命令传播阶段–心跳机制在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。心跳机制对于主从复制的超时判断、数据安全等有作用。 主-&gt;从：PING 每隔指定的时间，主节点会向从节点发送PING命令，这个PING命令的作用，主要是为了让从节点进行超时判断。 PING发送的频率由repl-ping-slave-period参数控制，单位是秒，默认值是10s。 关于该PING命令究竟是由主节点发给从节点，还是相反，有一些争议；因为在Redis的官方文档中，对该参数的注释中说明是从节点向主节点发送PING命令。 从-&gt;主：REPLCONF ACK在命令传播阶段，从节点会向主节点发送REPLCONF ACK命令，频率是每秒1次；命令格式为：REPLCONF ACK {offset}，其中offset指从节点保存的复制偏移量 实时监测主从节点网络状态：该命令会被主节点用于复制超时的判断。此外，在主节点中使用info Replication，可以看到其从节点的状态中的lag值，代表的是主节点上次收到该REPLCONF ACK命令的时间间隔，在正常情况下，该值应该是0或1。 检测命令丢失：从节点发送了自身的offset，主节点会与自己的offset对比，如果从节点数据缺失（如网络丢包），主节点会推送缺失的数据（这里也会利用复制积压缓冲区）。注意，offset和复制积压缓冲区，不仅可以用于部分复制，也可以用于处理命令丢失等情形；区别在于前者是在断线重连后进行的，而后者是在主从节点没有断线的情况下进行的。 辅助保证从节点的数量和延迟：Redis主节点中使用min-slaves-to-write和min-slaves-max-lag参数，来保证主节点在不安全的情况下不会执行写命令；所谓不安全，是指从节点数量太少，或延迟过高。例如min-slaves-to-write和min-slaves-max-lag分别是3和10，含义是如果从节点数量小于3个，或所有从节点的延迟值都大于10s，则主节点拒绝执行写命令。而这里从节点延迟值的获取，就是通过主节点接收到REPLCONF ACK命令的时间来判断的，即前面所说的info Replication中的lag值。 应用中的问题查看refer内容 refer: https://www.cnblogs.com/kismetv/p/9236731.html]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis内存模型和持久化(搬运)]]></title>
    <url>%2F2019%2F07%2F30%2FRedis%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Redis内存模型Redis内存统计使用info memory进行统计 123456789101112131415161718192021222324252627282930313233343536373839404142127.0.0.1:6379&gt; info memory# Memoryused_memory:853392used_memory_human:833.39Kused_memory_rss:3375104used_memory_rss_human:3.22Mused_memory_peak:853392used_memory_peak_human:833.39Kused_memory_peak_perc:100.01%used_memory_overhead:841150used_memory_startup:791384used_memory_dataset:12242used_memory_dataset_perc:19.74%allocator_allocated:1396056allocator_active:1724416allocator_resident:8605696total_system_memory:1929056256total_system_memory_human:1.80Gused_memory_lua:37888used_memory_lua_human:37.00Kused_memory_scripts:0used_memory_scripts_human:0Bnumber_of_cached_scripts:0maxmemory:0maxmemory_human:0Bmaxmemory_policy:noevictionallocator_frag_ratio:1.24allocator_frag_bytes:328360allocator_rss_ratio:4.99allocator_rss_bytes:6881280rss_overhead_ratio:0.39rss_overhead_bytes:-5230592mem_fragmentation_ratio:4.15mem_fragmentation_bytes:2562728mem_not_counted_for_evict:0mem_replication_backlog:0mem_clients_slaves:0mem_clients_normal:49694mem_aof_buffer:0mem_allocator:jemalloc-5.1.0active_defrag_running:0lazyfree_pending_objects:0 几个关键的内存属性字段 used_memory Redis分配器分配的内存总量（单位是字节），包括使用的虚拟内存（即swap）。 used_memory_rss Redis进程占据操作系统的内存（单位是字节），与top及ps命令看到的值是一致的；除了分配器分配的内存之外，used_memory_rss还包括进程运行本身需要的内存、内存碎片等，但是不包括虚拟内存。 mem_fragmentation_ratio used_memory_rss / used_memory的比值，该值越大，内存碎片越多，如果该值小于1，则表明使用了虚拟内存swap，需要对redis进行扩容，优化等操作。 一般来说，mem_fragmentation_ratio在1.03左右是比较健康的状态（对于jemalloc来说） mem_allocator Redis使用的内存分配器，在编译时指定；可以是 libc 、jemalloc或者tcmalloc，默认是jemalloc。 Redis内存划分redis除了内部数据会占用内存之外，也存在其他占用内存的地方。 Redis的内存占用主要可以划分为以下几个部分 数据(字符串、哈希、列表、集合、有序集合) 数据为最主要占用内存部分，这部分内存占用会统计在used_memory中。 进程本身运行需要的内存 redis进程本身运行需要内存，入代码，常量池等。因为这部分不是有jemalloc分配，因此不会统计在used_memory中。 子进程，比如AOF，RDB也会占用内存，但也不会统计在used_memory中 缓冲内存 缓冲内存包括客户端缓冲区、复制积压缓冲区、AOF缓冲区等。这部分内存由jemalloc分配，因此会统计在used_memory中。 内存碎片 内存碎片是Redis在分配、回收物理内存过程中产生的。不会统计在used_memory中。 Redis数据存储的细节直接查看refer内容 Redis持久化Redis高可用技术 持久化 持久化是最简单的高可用方法(有时甚至不被归为高可用的手段)，主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失。 复制 复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。 缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。 哨兵 在复制的基础上，哨兵实现了自动化的故障恢复。 缺陷：写操作无法负载均衡；存储能力受到单机的限制。 集群 通过集群，Redis解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。 Redis持久化类型 RDB 将数据保存到硬盘 AOF 将每次执行的写命令保存到硬盘 由于AOF持久化的实时性更好，即当进程意外退出时丢失的数据更少，因此AOF是目前主流的持久化方式，不过RDB持久化仍然有其用武之地。 RDB持久化RDB可以通过手动触发，或者自动触发 手动触发 在命令行界面执行save命令，或者bgsave命令。 save命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在Redis服务器阻塞期间，服务器不能处理任何命令请求。 bgsave命令会创建一个子进程，由子进程来负责创建RDB文件，父进程(即Redis主进程)则继续处理请求。 bgsave命令执行过程中，只有fork子进程时会阻塞服务器，而对于save命令，整个过程都会阻塞服务器，因此save已基本被废弃，线上环境要杜绝save的使用 自动触发 在配置文件中配置save m n，表示在m秒内发生n次变化时会触发bgsave。例如 save 900 1 表示在900秒内，如果redis数据发生了至少1次变化，则执行bgsave。多条save m n命令只要满足其中一条，就会触发。 在主从复制场景下，如果从节点执行全量复制操作，则主节点会执行bgsave命令，并将rdb文件发送给从节点。 执行shutdown命令时，自动执行rdb持久化。 save m n的实现原理 Redis的save m n，是通过serverCron函数、dirty计数器、和lastsave时间戳来实现的。 serverCron是Redis服务器的周期性操作函数，默认每隔100ms执行一次；该函数对服务器的状态进行维护，其中一项工作就是检查 save m n 配置的条件是否满足，如果满足就执行bgsave。 dirty计数器是Redis服务器维持的一个状态，记录了上一次执行bgsave/save命令后，服务器状态进行了多少次修改(包括增删改)；而当save/bgsave执行完成后，会将dirty重新置为0。例如，如果Redis执行了set mykey helloworld，则dirty值会+1；如果执行了sadd myset v1 v2 v3，则dirty值会+3；注意dirty记录的是服务器进行了多少次修改，而不是客户端执行了多少修改数据的命令。 lastsave时间戳也是Redis服务器维持的一个状态，记录的是上一次成功执行save/bgsave的时间。 save m n的原理如下 每隔100ms，执行serverCron函数；在serverCron函数中，遍历save m n配置的保存条件，只要有一个条件满足，就进行bgsave。对于每一个save m n条件，只有下面两条同时满足时才算满足 当前时间-lastsave &gt; m dirty &gt;= n bgsave执行流程bgsave执行流程图 五个步骤 Redis父进程首先判断：当前是否在执行save，或bgsave/bgrewriteaof（直接调用bgrewriteaof命令，该命令的执行与bgsave有些类似，都是fork子进程进行具体的工作，且都只有在fork时阻塞）的子进程，如果在执行则bgsave命令直接返回。bgsave/bgrewriteaof 的子进程不能同时执行，主要是基于性能方面的考虑：两个并发的子进程同时执行大量的磁盘写操作，可能引起严重的性能问题。 父进程执行fork操作创建子进程，这个过程中父进程是阻塞的，Redis不能执行来自客户端的任何命令。 父进程fork后，bgsave命令返回”Background saving started”信息并不再阻塞父进程，并可以响应其他命令。 子进程创建RDB文件，根据父进程内存快照生成临时快照文件，完成后对原有文件进行原子替换。 子进程发送信号给父进程表示完成，父进程更新统计信息。 bgsave加载 RDB文件的载入工作是在服务器启动时自动执行的。 由于AOF的优先级更高，因此当AOF开启时，Redis会优先载入AOF文件来恢复数据。 只有当AOF关闭时，才会在Redis服务器启动时检测RDB文件，并自动载入。 服务器载入RDB文件期间处于阻塞状态，直到载入完成为止。 Redis载入RDB文件时，会对RDB文件进行校验，如果文件损坏，则日志中会打印错误，Redis启动失败。 RDB常用配置总结 save m n bgsave自动触发的条件；如果没有save m n配置，相当于自动的RDB持久化关闭，不过此时仍可以通过其他方式触发 stop-writes-on-bgsave-error yes 当bgsave出现错误时，Redis是否停止执行写命令；设置为yes，则当硬盘出现问题时，可以及时发现，避免数据的大量丢失；设置为no，则Redis无视bgsave的错误继续执行写命令，当对Redis服务器的系统(尤其是硬盘)使用了监控时，该选项考虑设置为no rdbcompression yes 是否开启RDB文件压缩 rdbchecksum yes 是否开启RDB文件的校验，在写入文件和读取文件时都起作用；关闭checksum在写入文件和启动文件时大约能带来10%的性能提升，但是数据损坏时无法发现 dbfilename dump.rdb RDB文件名 dir ./ RDB文件和AOF文件所在目录 AOF持久化AOF持久化是将Redis执行的每次写命令记录到单独的日志文件中，当Redis重启时再次执行AOF文件中的命令来恢复数据。 与RDB相比，AOF的实时性更好，因此已成为主流的持久化方案。 开启AOF配置文件中appendonly yes 执行流程 命令追加(append)：将Redis的写命令追加到缓冲区aof_buf。 Redis先将写命令追加到缓冲区，而不是直接写入文件，主要是为了避免每次有写命令都直接写入硬盘，导致硬盘IO成为Redis负载的瓶颈。 文件写入(write)和文件同步(sync)：根据不同的同步策略将aof_buf中的内容同步到硬盘。 文件重写(rewrite)：定期重写AOF文件，达到压缩的目的。 appendfsync参数AOF缓存区的同步文件策略由参数appendfsync控制 always 命令写入aof_buf后立即调用系统fsync操作同步到AOF文件，fsync完成后线程返回。这种情况下，每次有写命令都要同步到AOF文件，硬盘IO成为性能瓶颈。 no 命令写入aof_buf后调用系统write操作，不对AOF文件做fsync同步；同步由操作系统负责，通常同步周期为30秒。这种情况下，文件同步的时间不可控，且缓冲区中堆积的数据会很多，数据安全性无法保证。 everysec 命令写入aof_buf后调用系统write操作，write完成后线程返回；fsync同步文件操作由专门的线程每秒调用一次。everysec是前述两种策略的折中，是性能和数据安全性的平衡，因此是Redis的默认配置，也是我们推荐的配置。 文件重写(rewrite)文件重写是指定期重写AOF文件，减小AOF文件的体积 AOF重写是把Redis进程内的数据转化为写命令，同步到新的AOF文件；不会对旧的AOF文件进行任何读取、写入操作 关于文件重写需要注意的另一点是：对于AOF持久化来说，文件重写虽然是强烈推荐的，但并不是必须的；即使没有文件重写，数据也可以被持久化并在Redis启动的时候导入；因此在一些实现中，会关闭自动的文件重写，然后通过定时任务在每天的某一时刻定时执行。 文件重写之所以能够压缩AOF文件的原因 过期的数据不再写入文件 无效的命令不再写入文件 如有些数据被重复设值(set mykey v1, set mykey v2)、有些数据被删除了(sadd myset v1, del myset)等等 多条命令可以合并为一个 如sadd myset v1, sadd myset v2, sadd myset v3可以合并为sadd myset v1 v2 v3。 文件重写的触发 手动触发 直接调用bgrewriteaof命令，该命令的执行与bgsave有些类似：都是fork子进程进行具体的工作，且都只有在fork时阻塞。 自动触发根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数，以及aof_current_size和aof_base_size状态确定触发时机。 auto-aof-rewrite-min-size 执行AOF重写时，文件的最小体积，默认值为64MB。 auto-aof-rewrite-percentage 执行AOF重写时，当前AOF大小(即aof_current_size)和上一次重写时AOF大小(aof_base_size)的比值。 只有当auto-aof-rewrite-min-size和auto-aof-rewrite-percentage两个参数同时满足时，才会自动触发AOF重写，即bgrewriteaof操作。 文件重写的流程重写流程图 Redis父进程首先判断当前是否存在正在执行 bgsave/bgrewriteaof的子进程，如果存在则bgrewriteaof命令直接返回，如果存在bgsave命令则等bgsave执行完成后再执行。 父进程执行fork操作创建子进程，这个过程中父进程是阻塞的。 父进程fork后，bgrewriteaof命令返回”Background append only file rewrite started”信息并不再阻塞父进程，并可以响应其他命令。Redis的所有写命令依然写入AOF缓冲区，并根据appendfsync策略同步到硬盘，保证原有AOF机制的正确。 由于fork操作使用写时复制技术，子进程只能共享fork操作时的内存数据。由于父进程依然在响应命令，因此Redis使用AOF重写缓冲区(图中的aof_rewrite_buf)保存这部分数据，防止新AOF文件生成期间丢失这部分数据。也就是说，bgrewriteaof执行期间，Redis的写命令同时追加到aof_buf和aof_rewirte_buf两个缓冲区。 子进程根据内存快照，按照命令合并规则写入到新的AOF文件。 子进程写完新的AOF文件后，向父进程发信号，父进程更新统计信息，具体可以通过info persistence查看。 父进程把AOF重写缓冲区的数据写入到新的AOF文件，这样就保证了新AOF文件所保存的数据库状态和服务器当前状态一致。 使用新的AOF文件替换老文件，完成AOF重写。 启动时加载 当AOF开启时，Redis启动时会优先载入AOF文件来恢复数据。 当AOF开启，但AOF文件不存在时，即使RDB文件存在也不会加载。 文件校验 Redis载入AOF文件时，会对AOF文件进行校验，如果文件损坏，则日志中会打印错误，Redis启动失败。 如果是AOF文件结尾不完整(机器突然宕机等容易导致文件尾部不完整)，且aof-load-truncated参数开启，则日志中会输出警告，Redis忽略掉AOF文件的尾部，启动成功。aof-load-truncated参数默认是开启的。 伪客户端因为Redis的命令只能在客户端上下文中执行，而载入AOF文件时命令是直接从文件中读取的，并不是由客户端发送；因此Redis服务器在载入AOF文件之前，会创建一个没有网络连接的客户端，之后用它来执行AOF文件中的命令，命令执行的效果与带网络连接的客户端完全一样。 AOF常用配置总结 appendonly no：是否开启AOF appendfilename “appendonly.aof”：AOF文件名 dir ./：RDB文件和AOF文件所在目录 appendfsync everysec：fsync持久化策略 no-appendfsync-on-rewrite no：AOF重写期间是否禁止fsync；如果开启该选项，可以减轻文件重写时CPU和硬盘的负载（尤其是硬盘），但是可能会丢失AOF重写期间的数据；需要在负载和安全性之间进行平衡 auto-aof-rewrite-percentage 100：文件重写触发条件之一 auto-aof-rewrite-min-size 64mb：文件重写触发提交之一 aof-load-truncated yes：如果AOF文件结尾损坏，Redis启动时是否仍载入AOF文件 方案选择与常见问题RDB和AOF的优缺点 RDB持久化 优点：RDB文件紧凑，体积小，网络传输快，适合全量复制；恢复速度比AOF快很多。当然，与AOF相比，RDB最重要的优点之一是对性能的影响相对较小。 缺点：RDB文件的致命缺点在于其数据快照的持久化方式决定了必然做不到实时持久化，而在数据越来越重要的今天，数据的大量丢失很多时候是无法接受的，因此AOF持久化成为主流。此外，RDB文件需要满足特定格式，兼容性差（如老版本的Redis不兼容新版本的RDB文件）。 AOF持久化 优点：于支持秒级持久化、兼容性好。 缺点：是文件大、恢复速度慢、对性能影响大。 策略选择等其他问题参见原文 https://www.cnblogs.com/kismetv/p/9137897.html refer https://www.cnblogs.com/kismetv/p/8654978.html]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络tcp_udp协议]]></title>
    <url>%2F2019%2F07%2F29%2F%E7%BD%91%E7%BB%9Ctcp_udp%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[tcphttp封装Ethernet2(以太网2帧头) | IPV4 | TCP | HTTP | FCS(以太网2帧尾) tcp端口号 取值范围 16bit 范围0-65535 0–2^16-1 1-1023 知名端口 1024-65535 非知名端口 tcp信道协议种类 单信道协议:一个应用程序对应一个端口 多信道协议:一个应用程序对应多个端口，比如ftp,tcp20(控制端口)和tcp21(数据端口) tcp对带宽抢占率远低于udp tcp头部封装 tcp header 取值范围20Byte-60Byte。 header length，因为长度可变，该字段告诉接受者tcp报头长度。 Resv. 保留字段全部置0。 6个控制位，syn置1 则表示发送syn，也就是三次握手的第一个阶段。 URG，服务器一对多处理报文的时候，如果tcp URG置为1，则优先对这些数据进行处理。 只有当需要对tcp启用高级功能的到时候，才需要添加options可选项 padding是因为三层包头和四层包头大小都必须被4整除，所以当options选项被使用的时候，无法被4整除的时候，对padding进行用连续的0填充，填充到可以被4整除 ergent pointer 紧急指针配合URG位，让多股tcp应用，哪一股被优先处理 三次握手 四次挥手 面向连接协议: 流量控制 限速，(源末两端接受带宽不一致，如果源端带宽大，全速发送给接收端，则接收端会产生拥塞。) 在发送数据之前进行协商速率，通过windown字段(单位字节，Byte)进行协商,比如协商为100字节，则源端发送100字节数据给接收端，接收端收到后，返回一个确认给源端，如果没确认，则表示数据丢失，需要数据重传。窗口不是固定不变，在每次发送流量之前都会进行windown协商。带宽大的时候，窗口经过协商会变大，直到占用链路最大字节的时候，又会控制窗口大小，防止拥塞发生，这种行为称之为滑动窗口。 tcp延迟启动(slow start) 第一次协商为1 字节， 第二次为2字节 第n次为2^(n-1)次方,(下载的时候先比较小，然后逐渐变大) 全局同步问题：slow start 窗口逐渐变大，当超出阈值带宽的时候，会减半，然后又逐渐变大，触发阈值再减半，依次循环。其带宽利用是一个折线。平均带宽利用不会百分百打满。当存在大量tcp应用的时候，此时这些应用一起发送数据的时候，就会出现全局同步的问题，大家都在利用带宽，发现不足了，瞬间减半窗口。 滑动窗口的协商发生在接收方回复syn-ack的时候。 防乱序 处理延迟，串行化延迟，传输延迟，队列延迟 队列延迟，导致源给目的地发送多个数据，导致乱序—-抖动。 通过squence number来标记数据包，进行顺序接受。 防丢包 acknowlegde number中包含一个确认号，确认号的值通常为发送方发送的最大序列号值加1。比如发送方发送 1 2 3 ，则接收方发送确认号4，发送方知道4后，接着发送4 5 6。如果接收方只收到了4 5 ，则其返回确认号为6，那么发送方发现接收方漏了6，则对6进行重发。 如果发送方只收到了4，返回了确认号5， 那么发送方会对 5 6 都重发。 完整性检查 根据接收到的数据跟tcp中的checksum字段比较。因为并不是HMAC的方式，所以无法检测数据是否被篡改，只能检测流量在发送的时候是否因为拥塞导致冲突。 数据重传 根据发送方发来的确认号，以及发送过去的序列号，对比查看是否需要重传。 tcp注意点 tcp只支持单播(unicast)数据的发送,如果用了tcp，则无法组播或者广播。相对udp不够灵活，udp支持单播 组播 广播。 完全连接，完成三次握手。 半开连接，发送端未发送最后一次ack的连接，接收端不会自动断开，会默认被保持，且消耗服务器内存和cpu。 udp面向无连接，不可靠传输 封装ip header | udp header | data udp头部报文 udp头部占用8字节，传输时候没有确认机制。 udp主持组播和广播 媒体流量基本用udp封装，所以媒体对序列的要求，则封装一个rtp(实时传输协议)的包头，其squence 为12字节，保证源末报文可以根据序列进行重组。 ethernet2 | udp | rtp | VoIP | FCS tcp udp对比 可靠 tcp强 安全 udp强 tcp 三次握手容易被攻击 带宽利用 udp利用高 tcp存在全局同步的问题，解决办法 QoS WRED加权随机早期检测 应用灵活 tcp只支持单播，udp更加灵活 不用支持重传的服务 VoIP 用udp]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[误删正在输出的tomcat服务日志]]></title>
    <url>%2F2019%2F04%2F17%2F%E8%AF%AF%E5%88%A0%E6%AD%A3%E5%9C%A8%E8%BE%93%E5%87%BA%E7%9A%84%E6%9C%8D%E5%8A%A1%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[误删场景今天find写日志切割tomcat日志，需要匹配后缀为log,out,txt，之后忘记写括号,将log和out删除了。 1/usr/bin/find /opt/*/logs/* ( -name &quot;*.out&quot; -o -name &quot;*.log&quot; -o -name &quot;*.txt&quot; ) -mtime +30 | xargs -I &#123;&#125; rm -f &#123;&#125; tomcat不像nginx那样可以reload，其需要整个暂停，然后启动才能重新生成日志文件，但如果重启tomcat，则war包加载需要的时间比较长，且这段时间无法提供服务。 临时查看的方法虽然日志文件被删除，但在tomcat没有关闭之前文件描述符还是存在的，只是软连对象被删除而已。]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[做一个不专业的jenkins回滚]]></title>
    <url>%2F2019%2F04%2F11%2F%E5%81%9A%E4%B8%80%E4%B8%AA%E4%B8%8D%E4%B8%93%E4%B8%9A%E7%9A%84jenkins%E5%9B%9E%E6%BB%9A%2F</url>
    <content type="text"><![CDATA[war包回滚思路发布期间 对正在提供服务的war包在同目录下，重命名为xxx.warbak 并且对该war归档到指定目录 回滚期间 将同目录下war的备份文件还原成xxx.war 用到的组件如下: Customized Build Message Plugin（build后可以看到备注等自动传入的信息） Build With Parameters (build的时候选填参数) Git Parameter Plug-In (选择分支，tag等) Publish Over SSH (通过ssh方式发包) 配置介绍 每个publish over ssh的对象都存在两种情况，发布(deploy)和回滚(rollback)，所以需要对一个机器创建两个状态。 根据build的时候传入的参数，deploy还是rollback，选择对应的行为。 配置截图图小新开一个浏览器页面看 部分代码: 部署 123456[ -d &quot;/opt/$&#123;tomcat_dir&#125;/war&quot; ] &amp;&amp; echo &apos;back dir is exist&apos; || mkdir -p /opt/$&#123;tomcat_dir&#125;/war;cp /opt/$&#123;tomcat_dir&#125;/webapps/$&#123;tomcat_war&#125;.war /opt/$&#123;tomcat_dir&#125;/war/$&#123;tomcat_war&#125;.war_`date +&quot;%Y%m%d-%H%M&quot;` || echo &apos;not exist war&apos;;ps -ef | grep $&#123;tomcat_dir&#125; | grep -vP &quot;cronolog|grep&quot; | awk &apos;&#123;print $2&#125;&apos; | xargs -I &#123;&#125; kill &#123;&#125;;sleep 3;rm -rf /opt/$&#123;tomcat_dir&#125;/webapps/$&#123;tomcat_war&#125;;/bin/mv /opt/$&#123;tomcat_dir&#125;/webapps/$&#123;tomcat_war&#125;.&#123;war,warbak&#125; || echo &apos;not exist war&apos;; 回滚 12345ps -ef | grep $&#123;tomcat_dir&#125; | grep -vP &quot;cronolog|grep&quot; | awk &apos;&#123;print $2&#125;&apos; | xargs -I &#123;&#125; kill &#123;&#125;;sleep 3;rm -rf /opt/$&#123;tomcat_dir&#125;/webapps/$&#123;tomcat_war&#125;;/bin/mv /opt/$&#123;tomcat_dir&#125;/webapps/$&#123;tomcat_war&#125;.&#123;warbak,war&#125; || echo &apos;not exist war&apos;;/opt/$&#123;tomcat_dir&#125;/bin/catalina.sh start; 存在问题 由于采用的是maven项目，所以不论发布还是回滚都是会进行war包的build，其实在回滚的时候是不需要进行war包的build的。 refer: http://www.eryajf.net/1404.html]]></content>
      <tags>
        <tag>cicd</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git rebase操作]]></title>
    <url>%2F2019%2F03%2F26%2Fgit-rebase%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[同一分支 不同文件 无冲突情况 本地修改master，远端(模拟其他协同开发人员)修改remote_change 12$ lsmaster remote_change 查看当前git log信息 1234huangyisan@huangyisan-PC MINGW64 ~/Desktop/github/pingan/testgit (master)$ git log --graph --pretty=oneline --abbrev-commit* aed5259 (HEAD -&gt; master, origin/master) local change 2* d327114 local change 1 当前分支指向master，且和远程对齐。 非本地进行提交比如使用web页面gitlab提交，模拟协同操作仓库，修改remote_change内容 然后本地进行提交修改master文件内容两次，并且commit，进行push 1234567$ git commit -m &apos;local change 3&apos;[master d327114] local change 3 1 file changed, 1 insertion(+), 1 deletion(-) $ git commit -m &apos;local change 4&apos;[master aed5259] local change 4 1 file changed, 1 insertion(+), 1 deletion(-) 进行push，此时因为非本地端已经被提交，当前仓库不是最新代码，push被rejected，查看git log内容 123456$ git log --graph --pretty=oneline --abbrev-commit* 8dd9d20 (HEAD -&gt; master) local change 4* f6b8c95 local change 3* aed5259 (origin/master) local change 2* d327114 local change 1* d0e5f73 change local 17 当前位置比远程仓库快2个位置。由于远程已经有提交内容，本地仓库不是最新代码，需要git pull. 仓库重新pull，并查看git log 123456789$ git log --graph --pretty=oneline --abbrev-commit* 5b4b59f (HEAD -&gt; master) Merge branch &apos;master&apos; of http://gitlab.ptest.cdn.pingan.com.cn:19090/huangyisan/testgit|\| * 3fb5469 (origin/master) 更新 remote_change 1* | 8dd9d20 local change 4* | f6b8c95 local change 3|/* aed5259 local change 2* d327114 local change 1 此时出现了’分叉’，本地指向的是和远程merge的内容，但远程是指向3fb5469位置，还没更新本地的两个commit提交内容。 使用rebase，查看git log 1234$ git rebaseFirst, rewinding head to replay your work on top of it...Applying: local change 3Applying: local change 4 查看git log 123456$ git log --graph --pretty=oneline --abbrev-commit* c10a76b (HEAD -&gt; master) local change 4* 4101717 local change 3* 3fb5469 (origin/master) 更新 remote_change 1* aed5259 local change 2* d327114 local change 1 此时git log变成了一条直线。查看git log内容更加清晰明了。本地指向c10a76b 远端仓库指向3fb5469，还需要对本地进行git push git push提交更变内容由于只是rebase，并没有git push，所以还需要把本地的量词修改提交到远端仓库 123456789$ git pushEnumerating objects: 8, done.Counting objects: 100% (8/8), done.Delta compression using up to 4 threadsCompressing objects: 100% (4/4), done.Writing objects: 100% (6/6), 569 bytes | 569.00 KiB/s, done.Total 6 (delta 0), reused 0 (delta 0)To http://xxxxxxxxxxxxxxxxxxxxxxx 3fb5469..c10a76b master -&gt; master 同一分支 相同文件 有冲突情况 查看git log信息 123$ git log --graph --pretty=oneline --abbrev-commit* d01191c (HEAD -&gt; master, origin/master) local change 1* 6b113ef remove 本地和远端都修改master文件，让其产生冲突 本地: 12$ cat masterlocal change 2 远端: 12local change 1remote change 2 远端提交，然后本地也push 本地不是指向最新的commit，本地需要先pull 本地pull操作，出现了冲突 git status内容 12345678910111213141516$ git statusOn branch masterYour branch and &apos;origin/master&apos; have diverged,and have 1 and 1 different commits each, respectively. (use &quot;git pull&quot; to merge the remote branch into yours)You have unmerged paths. (fix conflicts and run &quot;git commit&quot;) (use &quot;git merge --abort&quot; to abort the merge)Unmerged paths: (use &quot;git add &lt;file&gt;...&quot; to mark resolution) both modified: masterno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 冲突内容 1234567$ cat master&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADlocal change 2=======local change 1remote change 2&gt;&gt;&gt;&gt;&gt;&gt;&gt; 2497b92a10abea64a2cfc7072039bbf497cc11e0 add commit冲突内容 此时如果修改冲突内容然后rebase，则修改的内容又会还原，所以先add commit 12$ git commit -m &apos;conficlit&apos;[master a252b15] conficlit 查看git log，发现出现分叉了 123456$ git log --graph --pretty=oneline --abbrev-commit* a252b15 (HEAD -&gt; master) conficlit|\| * 2497b92 (origin/master) 更新 master* | 92bf8fc local change 2|/ 此时进行git rebase操作查看git log 之前的分叉没了 12345$ git log --graph --pretty=oneline --abbrev-commit* 2497b92 (HEAD, origin/master) 更新 master* d01191c local change 1* 6b113ef remove* f6e9fe8 update 然后修复冲突，并且进行add 修复冲突后 add，但不commit 1$ git add master 进行git rebase –continue操作 12$ git rebase --continueApplying: local change 2 查看git log, 此时本地HEAD比远端快，所以需要push 1234$ git log --graph --pretty=oneline --abbrev-commit* 455b381 (HEAD -&gt; master) local change 2* 2497b92 (origin/master) 更新 master* d01191c local change 1 最后进行git push 查看git log 测试及本地HEAD和远端对齐commit号了 123456$ git log --graph --pretty=oneline --abbrev-commit* 455b381 (HEAD -&gt; master, origin/master) local change 2* 2497b92 更新 master* d01191c local change 1* 6b113ef remove* f6e9fe8 update 不同分支 无冲突情况 dog cat两个基于master checkout出来的分支，当前git log出现分叉 在cat分支上进行git rebase dog 1234$ git rebase dogFirst, rewinding head to replay your work on top of it...Applying: catApplying: cat 查看git log ，cat和dog的分叉合并了 不同分支 有冲突情况 dog cat两个基于master checkout出来的分支，当前git log出现分叉 在cat分支上进行git rebase dog 出现了冲突 12345678910111213141516171819202122$ git rebase dogFirst, rewinding head to replay your work on top of it...Applying: catApplying: catApplying: remove cat dogUsing index info to reconstruct a base tree...A dogFalling back to patching base and 3-way merge...Removing catApplying: catUsing index info to reconstruct a base tree...Falling back to patching base and 3-way merge...Auto-merging annimalCONFLICT (add/add): Merge conflict in annimalerror: Failed to merge in the changes.hint: Use &apos;git am --show-current-patch&apos; to see the failed patchPatch failed at 0004 catResolve all conflicts manually, mark them as resolved with&quot;git add/rm &lt;conflicted_files&gt;&quot;, then run &quot;git rebase --continue&quot;.You can instead skip this commit: run &quot;git rebase --skip&quot;.To abort and get back to the state before &quot;git rebase&quot;, run &quot;git rebase --abort&quot;. 解决冲突后，git add ，然后git rebase --continue 无需git commit 1234$ git add annimal$ git rebase --continueApplying: cat 查看git log已经解决分叉情况 结论 只对尚未推送或分享给别人的本地修改执行变基操作清理历史 从不对已推送至别处的提交执行变基操作 如果存在冲突，则解决完冲突后，进行git add，之后不需要git commit，直接使用git rebase --continue rebase目的就是让协同开发同事看log更加清晰明了。 refer https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0015266568413773c73cdc8b4ab4f9aa9be10ef3078be3f000#0http://gitbook.liuhui998.com/4_2.htmlhttps://www.youtube.com/watch?v=HeF7dwVyzow&amp;feature=player_embedded]]></content>
      <tags>
        <tag>linux</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[布隆过滤器]]></title>
    <url>%2F2019%2F03%2F19%2F%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%2F</url>
    <content type="text"><![CDATA[判断value是否存在 常用判断某个value是否存在特定集合中，一般用hashmap，但hashmap存储量较高。 布隆过滤器相对于hashmap而言，牺牲了准确性，但大大降低了空间利用率。 布隆过滤器对值的判断存在两种情况，可能存在和绝对不存在。 原理布隆过滤器两个要素，长度为n的bit array和m个独立的hash function。对需要写入的数值value进行所有的hash function运算，得到的值和n进行取模运算，得到m个位置，把bit array的这些位置置为1，就完成了一次写入。 举个简单的例子 需要存入的值为’huangyisan’，bit arrary长度为10。 存在三个hash方法，分别对huangyisan运算。 然后对函数执行得到的结果，和长度10取模。 取模得到的值，在bit arrary中对应位置至于1。 那么只要bit arrary的3 5 9 位为1，则代表huangyisan这个字符串存在。 存在的问题布隆过滤器的两个状态，一个为绝对不存在(negative)，还有一个为可能存在(positive)。所以这个可能存在的状态，会使得得到的结果不一定准确。出现这个情况，主要是存入数据比较多，导致bit位重叠，所以单单根据bit位为1判断某个字符串是否存在，只能判断为可能存在。所以在对准确性有一定容忍度的环境，是可以使用布隆选择器的。 问题最大可能进行避免问题肯定能存在，但可以降低产生的概率，此时就要在使用之前对bit arrary长度，hash function数量等因素进行设定。一个可以进行评估设定的站点: https://hur.st/bloomfilter/?n=4000&amp;p=1.0E-7&amp;m=&amp;k=2 python实现布隆过滤器12345678910111213141516171819202122232425262728293031323334353637383940import hashlibclass BloomFilter(object): def __init__(self,size): self.size = size self.arrarylist = [0]*size self.hash_func = [hashlib.md5, hashlib.sha1, hashlib.sha224] def add_data(self,data): for func in self.hash_func: index = int(func(data.encode()).hexdigest(),16) % self.size self.arrarylist[index] = 1 def is_data_exist(self,data): result = 1 #起始位为1，如果为0，则肯定最终结果为0了。 for func in self.hash_func: index = int(func(data.encode()).hexdigest(),16) % self.size #三个index对应value，&amp;操作为1，则返回true result &amp;= self.arrarylist[index] return True if result == 1 else Falseif __name__ == &apos;__main__&apos;: # 调整bf_size大小，可以改变False positive的值 bf_size = 1000 bloom_filter = BloomFilter(bf_size) arrarylist = [] # 添加数值0-99 for i in range(100): bloom_filter.add_data(str(i)) # 对100-999进行is_data_exist方法运算，若返回true，则count+1，计算False positive的值。 count = 0 for i in range(100,1000): if bloom_filter.is_data_exist(str(i)): count+=1 print(&apos;False positive is &#123;0:.2f&#125;%&apos;.format(count/len(range(100,1000))*100)) refer https://medium.com/@Kadai/%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E5%A4%A7%E4%BE%BF%E7%95%B6-bloom-filter-58b0320a346dhttps://hur.st/bloomfilter/?n=4000&amp;p=1.0E-7&amp;m=&amp;k=2https://zhuanlan.zhihu.com/p/43263751]]></content>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python增删可迭代对象]]></title>
    <url>%2F2019%2F03%2F08%2Fpython%E5%A2%9E%E5%88%A0%E5%8F%AF%E8%BF%AD%E4%BB%A3%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[问题描述 直接迭代对象删除列表中所有的数字4。 1234567w = [1,2,3,4,4,5,6]for i in w: if i == 4: w.remove(i)print(w)[1, 2, 3, 4, 5, 6] 输出结果中，并没有删除所有的数字4。 使用len()方式删除列表中所有的数字4。 12345678w = [1,2,3,4,4,5,6]for i in range(len(w)): if w[i] == 4: w.remove(w[i])print(w)IndexError: list index out of range 出现IndexError错误。 产生原因 第一种是因为数组长度变小，迭代时候，指向出现了偏差，使用调试模式就能发现，当删除第一个”4”后，指针指向了第二个4，然后从第二个4开始迭代，此时跳过了第二个4的存在。 第二种是因为数组长度变小了，但len()记录的长度没变，所以导致了后面迭代的时候out of index。 解决方法如果能保证迭代的时候的对象不会因为原对象的改变而改变，就可以解决，也就是说对原对象进行copy，而不是引用。 列举两种处理方法： 使用[:]的方式 1234567w = [1,2,3,4,4,5,6]for i in w[:]: if i == 4: w.remove(i)print(w)[1, 2, 3, 5, 6] 使用deepcopy的方式 1234567891011import copyw = [1,2,3,4,4,5,6]for i in copy.deepcopy(w): if i == 4: w.remove(i)print(w)[1, 2, 3, 5, 6]]]></content>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[prometheus曲线救国添加hostname]]></title>
    <url>%2F2019%2F03%2F07%2Fprometheus%E6%B7%BB%E5%8A%A0hostname%2F</url>
    <content type="text"><![CDATA[问题场景 prometheus scrape_configs采用的是file_sd_configs，通过这种方式获取到的node_exporter的metric，元数据不存在hostname信息。 只看ip，无法知道该机器的用户。 grafana展现的时候，能根据hostname进行选择，展现机器数据。 方法 node_exporter中启用textfile采集的方式。 在textfile目录下，写入hostname。 通过表达式获取hostname。 待解决的问题 如何做到hostname的更变。 表达式hostname只和写入的metric有关，如何关联到不存在hostname的metric中。 解决方法 针对hostname的更变，让node_exporter启动的时候就进行自动读取当前hostname，并且写入。如果是配合supervisord或者systemd，则很好实现，比如用systemd守护的方式的时候，可以启用ExecStartPre方法，启动之前执行命令。 123456ExecStartPre=/opt/scripts/gethostname.sh# cat /opt/scripts/gethostname.sh#!/bin/bashecho -e &quot;# HELP hardware_status check hardware status.\n# TYPE machine_role gauge\nmachine_role&#123;role=\&quot;`/usr/bin/hostname`\&quot;&#125; 0&quot; &gt; /app/local/node_exporter/collect/hostname.promecho 1 &gt; /dev/null 让不存在metric的hostname关联，则需要一个共同的连接点，类似sql中的两表查询。先看hostname的metric 123# HELP machine_role Metric read from /app/local/node_exporter/collect/hostname.prom# TYPE machine_role gaugemachine_role&#123;role=&quot;postfix01&quot;&#125; 0 其label是role，value是postfix01，也就是hostname prometheus中执行执行machine_role,可以得到element为：1machine_role&#123;instance=&quot;10.1.11.1:9100&quot;,ip=&quot;10.1.11.1&quot;,job=&quot;L3&quot;,role=&quot;ShangHai-SJ-L3-LC-Flume-01&quot;,service=&quot;L3&quot;&#125; 这边有role和instance这个两个label，其中role为hostname的label，而instance则作为连接点的label。 在grafana中的变量配置中就可以根据machine_role，先获取role，作为$hostname的值1label_values(machine_role&#123;service=&quot;$job&quot;&#125;,role) 然后再根据$hostname，来获取instance,作为$node的值1label_values(machine_role&#123;role=&quot;$hostname&quot;&#125;,instance) 此时对grafana的表达式就可以使用$node值了，比如如下表达式，虽然node_cpu_seconds_total方法里面是不存在hostname的，但因为曲线救国的方式，通过$hostname取得$node，然后传入node_cpu_seconds_total方法中，则可以出现数据了。1count(count(node_cpu_seconds_total&#123;instance=~&quot;$node&quot;, mode=&apos;system&apos;&#125;) by (cpu)) 效果截图 先获取hostname。 再根据hostname获取node。隐藏了label，这个无所谓是否隐藏，我只是想知道具体ip是什么。 下拉通过hostname就可以选择机器了。 其他说明 如果是通过dns方式发现，则是可以把hostname变成元label的。 通过consul发现，则可以在consul客户端上报hostname，也可以把hostname变成元label。 待解决问题第二点解决方法promSQL可以使用on ignore group_left group_right配合来把hostname拼凑进去。 machine_role查询得到的结果: 1machine_role&#123;instance=&quot;10.1.11.1:9100&quot;,ip=&quot;10.1.11.1&quot;,job=&quot;L3&quot;,role=&quot;zabbix&quot;,service=&quot;L3&quot;&#125; 0 up查询得到的结果: 1up&#123;instance=&quot;10.1.11.1:9100&quot;,ip=&quot;10.1.11.1&quot;,job=&quot;L3&quot;,service=&quot;L3&quot;&#125; 1 machine_role里面的role标签包含了主机名，但up没有，此时通过将两个方法结合在一起。使用on方法，可以理解为mysql的两表查询join 两者的有共同的instance,job,service,ip标签 不一定要全部都选择，但选择的多则相互匹配更加精确，on(instance,job,service,ip) 使用group_left或者group_right标记”多”的标签,这边多出来的标签是role，所以为group_left(role) 表达式架构为: 1&lt;vector expr&gt; &lt;bin-op&gt; on(&lt;label list&gt;) group_left(&lt;label list&gt;) &lt;vector expr&gt; 指加减乘除余幂 所以将up和machine_role拼凑和可以写为 12up + on(instance, job,ip,service) group_left(role) machine_role&#123;instance=&quot;10.1.11.1:9100&quot;,ip=&quot;10.1.11.1&quot;,job=&quot;L3&quot;,role=&quot;zabbix&quot;,service=&quot;L3&quot;&#125; 1 如果用group_right，则把up和machine_role反一下即可 1machine_role + on(instance, job,ip,service) group_right(role) up 此时得到的结果包含了role，如果作为告警，由于up为1表示正常，machine_role设置的是0，两者相加，若为0，则表示机器down。告警表达式可以写成: 1up + on(instance, job,ip,service) group_left(role) machine_role == 0 此时如果告警，则会包含role这个标签，就可以传递给alertmanager，获取到role了。 refer https://www.robustperception.io/how-to-have-labels-for-machine-roleshttps://yunlzheng.gitbook.io/prometheus-book/parti-prometheus-ji-chu/promql/prometheus-promql-operators-v2]]></content>
      <tags>
        <tag>prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[position属性relative和absolute]]></title>
    <url>%2F2019%2F03%2F06%2Fposition%E5%B1%9E%E6%80%A7relative%E5%92%8Cabsolute%2F</url>
    <content type="text"><![CDATA[我还记得那个调整了3个多小时才把确认按钮移动到table右边的夜晚。以至于前端给我的错觉就是，我写出我的思路，但它却不这么去展现。。mmp..至此拾起来，从把relative和absolute两个属性搞清楚开始。 非嵌套在标签的情形初始代码:123456789101112131415161718192021222324252627282930&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;position.css&quot;&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=&quot;first&quot;&gt;class first&lt;/div&gt;&lt;div class=&quot;second&quot;&gt;class second&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;*&#123; margin: 0; padding: 0;&#125;.first&#123; width: 100px; height: 100px; background-color: #5060ff;&#125;.second&#123; width: 200px; height: 200px; background-color: #ff7276;&#125; 两个div挨在一起。 relative 添加position:relative等属性12345678.first&#123; position: relative; top: 50px; left: 50px; width: 100px; height: 100px; background-color: #5060ff;&#125; 蓝色背景的div根据top和left参数，位置上发生了改变。而红色div位置没有改变。 absolute 添加position:absolute等属性12345678.first&#123; position: absolute; top: 50px; left: 50px; width: 100px; height: 100px; background-color: #5060ff;&#125; 蓝色背景div根据top和left参数，位置上发生了改变，并且红色的div位置也发生了改变，和页面的顶部左边靠紧。 嵌套在标签的情形初始代码:123456789101112131415161718192021222324252627282930313233343536373839&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;position.css&quot;&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=&quot;first&quot;&gt; &lt;div class=&quot;second&quot;&gt; &lt;div class=&quot;third&quot;&gt;&lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;*&#123; margin: 0; padding: 0;&#125;.first&#123; width: 200px; height: 200px; background-color: #5060ff;&#125;.second&#123; width: 100px; height: 100px; background-color: #ff7276;&#125;.third&#123; width: 50px; height: 50px; background-color: #ffe43e;&#125; 三个方块重叠在一起 relative 给third添加relative等属性 12345678.third&#123; position: relative; top: 20px; left: 20px; width: 50px; height: 50px; background-color: #ffe43e;&#125; 黄色背景div基于原来位置根据top和left参数，位置上发生了改变。 再给second添加属性，去掉之前third的属性 1234567891011121314151617.second&#123; position: relative; top: 30px; left: 30px; width: 100px; height: 100px; background-color: #ff7276;&#125;.third&#123;&lt;!-- position: relative; top: 70px; left: 70px; --&gt; width: 50px; height: 50px; background-color: #ffe43e;&#125; 黄色背景div跟随红色背景div移动。 恢复third的属性 1234567891011121314151617.second&#123; position: relative; top: 30px; left: 30px; width: 100px; height: 100px; background-color: #ff7276;&#125;.third&#123; position: relative; top: 70px; left: 70px; width: 50px; height: 50px; background-color: #ffe43e;&#125; 黄色背景div在基于原来位置的基础上根据top和left参数，发生了改变。 absolute 给third添加absolute等属性 12345678.third&#123; position: absolute; top: 70px; left: 70px; width: 50px; height: 50px; background-color: #ffe43e;&#125; 黄色背景div根据top和left参数，发生了变化。 再给second添加属性 12345678910111213141516 position: relative; top: 30px; left: 30px; width: 100px; height: 100px; background-color: #ff7276;&#125;.third&#123; position: absolute; top: 70px; left: 70px; width: 50px; height: 50px; background-color: #ffe43e;&#125; 黄色背景div依据红色背景div再根据top和left参数，发生了变化。 去除second的属性，给first添加属性 1234567891011121314151617181920212223242526.first&#123; position: relative; top: 70px; left: 70px; width: 200px; height: 200px; background-color: #5060ff;&#125;.second&#123; /*position: relative;*/ /*top: 30px;*/ /*left: 30px;*/ width: 100px; height: 100px; background-color: #ff7276;&#125;.third&#123; position: absolute; top: 70px; left: 70px; width: 50px; height: 50px; background-color: #ffe43e;&#125; 黄色背景div依据蓝色背景div再根据top和left参数，发生了变化。 结论 absolute 脱离原来的位置(因为脱离原来的位置，所以其他元素可能会对原有位置进行占用)进行移动定位。 如果最近有父级，则根据父级定位，如果没有，则根据文档定位(因为body是最大的父级) relative 保留原来的位置，进行移动定位。 即便存在父级，也是相对(父级元素位置变动，相对位置也会变动)原来的位置进行移动定位。 absolute和relative配合 一般父级用relative做架子参照物，子级用absolute进行定位。 static和fixed static定位为默认情况，不会参照任何元素进行定位，按照浏览器预设的配置自动排版在页面上。 fixed相对浏览器视窗定位，一直固定一个相同的位置，不会受到浏览器滚动条的影响。 refer https://www.jianshu.com/p/f946aca4d6b0]]></content>
      <tags>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS选择器权重]]></title>
    <url>%2F2019%2F03%2F05%2Fcss%E9%80%89%E6%8B%A9%E5%99%A8%E6%9D%83%E9%87%8D%2F</url>
    <content type="text"><![CDATA[CSS选择器类型 id选择器#id 12345&lt;div id=&quot;mySelector&quot;&gt;this is id selector&lt;/div&gt;#mySelector&#123; color: #ff4400;&#125; class选择器.class 12345&lt;div class=&quot;myClass&quot;&gt;this is class selector&lt;/div&gt;.myClass&#123; color:#F10882;&#125; *选择器\* 123* &#123; font-style: italic;&#125; 元素选择器element 12345&lt;p&gt;this is p&lt;/p&gt;p&#123; color:green;&#125; 伪类:hover 12345&lt;a href=&quot;https://www.baidu.com&quot;&gt;www.baidu.com&lt;/a&gt;a:hover&#123; background-color: #f40;&#125; 父子选择器element elementelement&gt;element 1234567891011&lt;div&gt; &lt;p&gt;this is p in div&lt;/p&gt;&lt;/div&gt;div p&#123; color:#ff4400;&#125;div&gt;p&#123; color:green;&#125; 属性选择器[attribute=value] 1234&lt;div class=&quot;myclass&quot;&gt;this is div&lt;/div&gt;[class=myclass]&#123; color: #ff4400;&#125; 组选择器element,element1,element2 123456789&lt;div&gt;this is div&lt;/div&gt;&lt;span&gt;this is span&lt;/span&gt;&lt;p&gt;this is p&lt;/p&gt;div,span,p&#123; color:yellow;&#125; CSS选择器优先级优先级高的覆盖优先级低的样式。!important &gt; 行间样式(直接元素内写style=xxx的方式) &gt; id &gt; class | 属性 &gt; 标签选择器 &gt; 通配符其规则其实是由选择器权重实现的。 CSS选择器权重权重大的覆盖权重小的，不同的选择器有不同的权重。 !important Infinity 行间样式 1000 id 100 class | 属性 | 伪类 10 标签 | 伪元素 1 通配符 0 进制据说是265。]]></content>
      <tags>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sed的一些操作]]></title>
    <url>%2F2019%2F02%2F27%2Fsed%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[原始文件redis.conf内容：1234567891011121314151617input &#123; redis &#123; host =&gt; &quot;127.0.0.1:6379&quot; key =&gt; &quot;logstash:demo&quot; data_type =&gt; &quot;list&quot; codec =&gt; &quot;json&quot; type =&gt; &quot;logstash-redis-demo&quot; tags =&gt; [&quot;logstashdemo&quot;] &#125;&#125;output &#123; elasticsearch &#123; host =&gt; &quot;127.0.0.1:9200&quot; &#125;&#125; 获取sed匹配内容的下一行原始文件redis.conf内容: 思路：若要只抓取tags =&gt; [&quot;logstashdemo&quot;]内容，则需要匹配type =&gt; &quot;logstash-redis-demo&quot;这一行内容。 sed匹配内容下一行写法:sed -n &#39;/matchString/{n;p}&#39; filename 12[root@leanote ~]# sed -n &apos;/logstash-redis-demo/&#123;n;p&#125;&apos; redis.conf tags =&gt; [&quot;logstashdemo&quot;] 替换sed匹配行内容的下一行的指定内容 思路：先匹配到tags =&gt; [&quot;logstashdemo&quot;]内容，然后对该内容下一行内容tags =&gt; [&quot;logstashdemo&quot;]的logstashdemo改为replacedemo sed替换匹配行下一行内容写法:sed -i &#39;/查询匹配的内容/{n;s/下一行内要被替换的内容/替换内容/;}&#39; filename 123456789101112131415161718[root@leanote ~]# sed -i &apos;/logstash-redis-demo/&#123;n;s/logstashdemo/replacedemo/;&#125;&apos; redis.conf [root@leanote ~]# cat redis.conf input &#123; redis &#123; host =&gt; &quot;127.0.0.1:6379&quot; key =&gt; &quot;logstash:demo&quot; data_type =&gt; &quot;list&quot; codec =&gt; &quot;json&quot; type =&gt; &quot;logstash-redis-demo&quot; tags =&gt; [&quot;replacedemo&quot;] &#125;&#125;output &#123; elasticsearch &#123; host =&gt; &quot;127.0.0.1:9200&quot; &#125;&#125; sed内容存在变量情况 方法一，将外部单引号用双引号替代 123456789101112131415161718192021[root@leanote ~]# echo $beitihuanlist[root@leanote ~]# echo $tihuan str[root@leanote ~]# sed -e &quot;/key/&#123;n;s/$&#123;beitihuan&#125;/$&#123;tihuan&#125;/;&#125;&quot; redis.conf input &#123; redis &#123; host =&gt; &quot;127.0.0.1:6379&quot; key =&gt; &quot;logstash:demo&quot; data_type =&gt; &quot;str&quot; codec =&gt; &quot;json&quot; type =&gt; &quot;logstash-redis-demo&quot; tags =&gt; [&quot;replacedemo&quot;] &#125;&#125;output &#123; elasticsearch &#123; host =&gt; &quot;127.0.0.1:9200&quot; &#125;&#125; 方法二，不修改外部单引号，将变量用单引号引起来 1234567891011121314151617[root@leanote ~]# sed -e &apos;/key/&#123;n;s/&apos;$&#123;beitihuan&#125;&apos;/&apos;$&#123;tihuan&#125;&apos;/;&#125;&apos; redis.conf input &#123; redis &#123; host =&gt; &quot;127.0.0.1:6379&quot; key =&gt; &quot;logstash:demo&quot; data_type =&gt; &quot;str&quot; codec =&gt; &quot;json&quot; type =&gt; &quot;logstash-redis-demo&quot; tags =&gt; [&quot;replacedemo&quot;] &#125;&#125;output &#123; elasticsearch &#123; host =&gt; &quot;127.0.0.1:9200&quot; &#125;&#125; 注意点如果变量存在特殊符号，比如/，那么此时这个符号会影响sed的分隔符，需要将sed分隔符替换成其他的。 sed对软连文件进行操作sed对软连文件进行操作，倘若不指定--follow-symlinks，则软连文件和原始文件会被拆分,原始文件不会被修改，而软连的文件会被修改，且变成一个独立文件。 sed操作没有指定--follow-symlinks 1234567[root@leanote conf]# lltotal 0lrwxrwxrwx 1 root root 16 Feb 27 10:58 redis.conf -&gt; /root/redis.conf[root@leanote conf]# sed -i &apos;/key/&#123;n;s/&apos;$&#123;beitihuan&#125;&apos;/&apos;$&#123;tihuan&#125;&apos;/;&#125;&apos; redis.conf [root@leanote conf]# lltotal 4-rw-r--r-- 1 root root 248 Feb 27 11:00 redis.conf sed操作指定--follow-symlinks 1234[root@leanote conf]# sed -i --follow-symlinks &apos;/key/&#123;n;s/&apos;$&#123;beitihuan&#125;&apos;/&apos;$&#123;tihuan&#125;&apos;/;&#125;&apos; redis.conf[root@leanote conf]# lltotal 0lrwxrwxrwx 1 root root 16 Feb 27 11:02 redis.conf -&gt; /root/redis.conf]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nonlocal的用法]]></title>
    <url>%2F2019%2F02%2F20%2Fnonlocal%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[作用nonlocal允许对嵌套的函数作用域中的名称进行赋值，并且把这样的名称的作用域查找限制在嵌套的函数内。nonlocal限制查找在嵌套的函数域内，且可以在函数域内进行赋值修改。 例子12345678910111213def tester(start): state = start def nested(label): print(label,state) return nestedF=tester(0)F(&apos;spam&apos;)F(&apos;ham&apos;)执行结果为spam 0ham 0 函数nested中print方法内的state变量引用了上一层tester函数中的state。 如果仅仅是引用变量，则不会出现问题，若是不使用nonlocal情况下对变量进行赋值操作，则出现报错: 12345678910111213141516171819def tester(start): state = start def nested(label): print(label,state) state += 1 # 对state变量进行了赋值操作，在nested函数中并没有单独定义state变量。 return nestedF=tester(0)F(&apos;spam&apos;)F(&apos;ham&apos;) 报错如下：huangyisan:~/Desktop/Python_project/Mage_edu $ python3 nonlocalfunc.pyTraceback (most recent call last): File &quot;nonlocalfunc.py&quot;, line 18, in &lt;module&gt; F(&apos;spam&apos;) File &quot;nonlocalfunc.py&quot;, line 13, in nested print(label,state)UnboundLocalError: local variable &apos;state&apos; referenced before assignment state因为在nested中没有被定义，所以无法被赋值，但可以引用上一层tester函数。 如果要定义，则需要用nonlocal函数对其进行声明：123456789101112131415def tester(start): state = start def nested(label): nonlocal state print(label,state) state += 1 return nestedF=tester(0)F(&apos;spam&apos;)F(&apos;ham&apos;)执行结果：spam 0ham 1 边界情况 nonlocal对象必须已经在一个嵌套的def作用域中被赋值过，否则会报错。(global则不需要预先对变量进行赋值。) 报错代码如下：1234567891011def tester(start): def nested(label): nonlocal state # 在nested外层函数，也就是tester函数中并没有对state变量进行赋值。 state = 1 print(label,state) state += 1 return nestedF=tester(0)F(&apos;spam&apos;)F(&apos;ham&apos;) 因为在state被nonlocal处理之前并没有对state进行赋值！ nonlocal只会在嵌套def的作用域内查找，查找范围永远不会出def作用域范围，即便在最外层全局有了定义这个变量，也不会去查找。如果要去全局变量查询，则使用global。 nonlocal查询会逐级往上查询，查询到一个立马返回,也就是会就近查询。 12345678910111213141516state = 0def tester(start): state = 1 def cisco(middle): state = 2 def nested(label): nonlocal state print(label, state) return nested return ciscoF=tester(0)F(1)(&apos;spam&apos;)输出结果为spam 2 因为在cisco这个函数中已经存在了state=2的赋值，所以不会再查询cisco上一层tester中的state。就近返回了state=2。]]></content>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链表基础]]></title>
    <url>%2F2019%2F02%2F18%2F%E9%93%BE%E8%A1%A8%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[链表定义链表（Linked list）是一种线性，但是并不会按线性的顺序存储数据，而是在每一个节点里存到下一个节点的指针(Pointer) 链表包含了内存块”节点”，以及记录下个或者上个节点地址的指针next。 链表常见结构 单链表 第一个节点称之为头节点，最后一个称之为尾节点。 每个节点分为两个部分。第一个部分是保存活显示关于节点的信息，第二个部分是存储下一个节点的地址。 单链表只能单方向遍历，且最后尾节点的下一个地址指针指向为NULL。 循环链表 首尾节点连接在一起，可以是单链表的首尾相连，也可以是双链表的首尾相连。 双向链表 双向链表有两个连接，一个指向前一个节点(若是头节点，则指向NULL)，另外一个指向下一个节点(若是尾节点，则指向NULL)。 链表的查找、插入、删除插入删除行为复杂度 对于数组而言，因为需要保证内存空间的连续性，当插入或者删除的时候，需要对数据进行搬迁(比如插入第二个位置，则原本第二个位置的数据”搬迁”到第三个位置，原本第三个位置的数据”搬迁”到第四个位置，以此类推)，这样才能保证连续,所以其时间复杂度为O(n)。 对链表而言，因为无需考虑数据的搬迁，只需要改变前后节点指针，所以其时间复杂度为O(1)。 查询行为复杂度 数组查询分两种，一种是根据下标索引查询，一种是查询具体数据，如果是第一种，则可以通过首地址和下标通过寻址公式查询得到，时间复杂度为O(1)，但第二种查询具体数据，则是O(n)。 链表的查询则因为需要依次遍历，所以其查询复杂度为O(n)。 链表和数组 数组需要一块连续的内存空间。如果连续空间不足以被申请，即便总内存足够，也会创建数组失败。 链表不需要连续的内存空间，他通过指针将一组零散的内存块串联起来。 链表因为需要额外对指针进行存储，所以内存空间使用比数组要大。 cpu从内存读取数据，会先把读取到的数据加载到cpu的缓存中。从内存读取数据并不只是读取特定的访问地址，而是一个的数据块并存入cpu缓存中，然后下次查询的时候会先从cpu缓存中查询，如果找不到就从内存中查询，对于数组，读取某个下标对应的值后，其因为是连续的内存，所以会被一并存入cpu缓存中，而链表不会。 refer https://zh.wikipedia.org/wiki/%E9%93%BE%E8%A1%A8https://www.cnblogs.com/springfor/p/3985333.htmlhttps://time.geekbang.org/]]></content>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树种类和遍历]]></title>
    <url>%2F2019%2F02%2F12%2F%E4%BA%8C%E5%8F%89%E6%A0%91%E7%A7%8D%E7%B1%BB%E5%92%8C%E9%81%8D%E5%8E%86%2F</url>
    <content type="text"><![CDATA[二叉树种类二叉树种类定义没有一个标准化，所以不同文档可能有不同解释。 rooted binary tree 存在根节点，并且每个节点都有2个子节点。 full binary tree 每个节点只有0个或者2个子节点。 complete binary tree 除去最后一级，其他级都是full状态(0个或者2个子节点)，且最后一级的节点都在左侧子树上。 perfect binary tree 内节点都有两个子节点，且所有子叶都处于同一级别。 infinite complete binary tree every node has two children (and so the set of levels is countably infinite). The set of all nodes is countably infinite, but the set of all infinite paths from the root is uncountable, having the cardinality of the continuum 我的理解就是无穷尽的rooted binray tree balanced binary tree 左右子树高度差不超过1 且左右子树各自均为平衡二叉树 degenerate tree 每个节点只包含一个子节点。 遍历方式前序遍历(深度优先) 指先访问根，然后访问子树的遍历方式。 顺序 F, B, A, D, C, E, G, I, H. 堆栈代码实现:1234567891011121314151617181920212223242526272829303132333435363738class BinTree(object): def __init__(self,root): # 所有的点都是子节点，也是父节点的叶子。 self.root = root self.left = None self.right = None def preorder(self, root): if root is None: return stack = [] node = root while node or stack: while node: # 打印出根节点 print(node.root) # 然后将根节点放入stack中 stack.append(node) # 重新定义node为左节点 node = node.left # 一个个从栈中弹出，其实是压入栈中的根节点 node = stack.pop() # 打印跟的右侧子节点 node = node.right#以下遍历方式通用。 root = BinTree(&apos;F&apos;)root.left = BinTree(&apos;B&apos;)root.right = BinTree(&apos;G&apos;)root.left.left = BinTree(&apos;A&apos;)root.left.right = BinTree(&apos;D&apos;)root.left.right.left = BinTree(&apos;C&apos;)root.left.right.right = BinTree(&apos;E&apos;)root.right.right = BinTree(&apos;I&apos;)root.right.right.left = BinTree(&apos;H&apos;)# 选择执行对应的遍历方法。root.preorder(root) 解释：从最顶层的根进入，然后打印出这个根，并且压入栈，然后获取这个根的左节点，依次循环，直到左节点无法获取到，然后出栈，这边出栈出来的为最后压入的根(也就是底层的左节点)，然后开始遍历其右边的子树，右边子树也是从左边开始，也是压入栈，依次循环。 中序遍历(深度优先) 指先访问左（右）子树，然后访问根，最后访问右（左）子树的遍历方式。 顺序 A, B, C, D, E, F, G, H, I. 堆栈代码实现:1234567891011121314151617181920212223class BinTree(object): def __init__(self,root): self.root = root self.left = None self.right = None def midorder(self,root): if root is None: return stack = [] node = root while node or stack: while node: # 根压入栈 stack.append(node) # 赋予左节点 node = node.left # 挨个弹出，从最底层的左节点弹出 node = stack.pop() # 打印左节点 print(node.root) # 节点赋予右节点，开始遍历右边部分，也是从最底层开始。 node = node.right 解释：因为是左右中的方式，所以root是最迟打印的，则先把左边的都依次压栈，然后压入最后一个，开始逐步弹出，弹出就打印一个，然后遍历弹出的右子树，也是一样的方法，依次循环，直到全部退出，打印出最顶层的root。 后序遍历(深度优先) 指先访问子树，然后访问根的遍历方式。子树先左后右在根节点。 顺序 A, C, E, D, B, H, I, G, F. 堆栈代码实现：123456789101112131415161718192021222324252627class BinTree(object): def __init__(self,root): self.root = root self.left = None self.right = None def backorder(self, root): if root is None: return mystack1 = [] # mystack2中存放的是后序遍历的节点数据。 mystack2 = [] node = root # mystack1压入顶层根 mystack1.append(node) while mystack1: node = mystack1.pop() # 判断是否有左或者右节点，这边控制的是下一次循环压栈到stack2的顺序。 if node.left: mystack1.append(node.left) if node.right: mystack1.append(node.right) # 将该数的根放入stack2中， mystack2.append(node) while mystack2: # 此时mystack2中已经存满了节点，挨个pop()出来的顺序就是后序遍历的次序。 print(mystack2.pop().root) 解释：因为顺序为从最左节点开始，且需要判断是否存在根的左右子节点，且不是连续，所以需要用到两个栈。mystack1放入的是当前遍历的节点，然后往mystack2中压入，这个行为之前还对节点进行左右判断，先往stack1中压入左边的节点，然后压入右边的节点，轮到下次循环的时候，后放入stack1中的(右子树)被先pop出来，然后被插入到stack2中，此时stack2中存放的顺序，根节点，然后右节点，接着左节点，依次循环，直到把stack2给压满。最后一个while执行的时候，按照左右根的顺序打印出来，就实现了。 层级遍历(广度优先) 广度优先遍历会先访问离根节点最近的节点。二叉树的广度优先遍历又称按层次遍历。算法借助队列实现。 顺序 F, B, G, A, D, I, C, E, H. 队列代码实现：123456789101112131415161718192021class BinTree(object): def __init__(self,root): self.root = root self.left = None self.right = None def levelorder(self, root): if root is None: return myqueue = [] node = root myqueue.append(node) while myqueue: # pop弹出第一个元素，这个是队列。 node = myqueue.pop(0) print(node.root) # 左右插入的顺序也是弹出的顺序。所以能保证平级打印输出。 if node.left: myqueue.append(node.left) if node.right: myqueue.append(node.right) 解释：通过队列方式实现，比较简单，抓到元素append进去，一左一右方式放入，弹出的时候弹出第一个元素，并且打印。 refer https://www.geeksforgeeks.org/binary-tree-set-3-types-of-binary-tree/https://en.wikipedia.org/wiki/Binary_tree#Types_of_binary_treeshttps://blog.yangx.site/2016/07/22/Python-binary-tree-traverse/https://zh.wikipedia.org/zh-hant/%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86]]></content>
      <tags>
        <tag>python3</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tcp_max_syn_backlog和net.core.somaxconn]]></title>
    <url>%2F2019%2F02%2F11%2Ftcp_max_syn_backlog%E5%92%8Csomaxconn%2F</url>
    <content type="text"><![CDATA[kernel 3.10.0-693.2.2.el7.x86_64 两个队列tcp的建联存在两种状态 incomplete connection queue 未建联的队列 completed connection queue 已建联的队列 未建联的队列 客户端发出syn请求，并且已经达到服务端，服务端返回syn+ack,等待对端响应ack时候的队列。 这些套接口处于SYN_RCVD状态。 已建联的队列 客户端发送建联请求，并且已经和服务端完成了三次握手，但此时这个socket还未被程序使用。(如何拿出来使用，则需要调用accept()函数) 这些套接口处于ESTABLISHED状态。 listen()和accept()函数三次握手图 一段python服务端网络编程代码： 1234567891011121314import sockets = socket.socket()host = &quot;0.0.0.0&quot;port = 12345s.bind((host, port))BACKLOG = 5s.listen(BACKLOG)while True: c, addr = s.accept() print(&quot;conn addr : &quot;, addr) c.send(&quot;hello word&quot;) c.close() 上述代码listen()和accept()解释如下 listen()函数listen()函数的主要作用就是将套接字(sockfd)变成被动的连接监听套接字(被动等待客户端的连接)。 accept()函数从处于 completed connection queue状态的连接队列头部取出一个已经完成的连接，如这个队列没有已经完成的连接，accept()函数就会阻塞，直到取出队列中已完成的用户连接为止。 如果程序不调用accept()函数，那么连接socket一直滞留在completed connection queue队列里面，进而未被程序消费使用。 比如如下代码: 123456789101112import socketimport times = socket.socket()host = &quot;0.0.0.0&quot;port = 12345s.bind((host, port))BACKLOG = 5s.listen(BACKLOG)print(&apos;listening&apos;)time.sleep(3600) somaxconnThe behavior of the backlog argument on TCP sockets changed with Linux 2.2. Now it specifies the queue length for completely established sockets waiting to be accepted, instead of the number of incomplete connection requests. If the backlog argument is greater than the value in /proc/sys/net/core/somaxconn, then it is silently truncated to that value; the default value in this file is 128. In kernels before 2.4.25, this limit was a hard coded value, SOMAXCONN, with the value 128. somaxconn用来指定系统定义的建联队列的长度(ESTAB状态的连接数量)。 若程序中定义的listen函数的backlog大于系统定义的，则以系统定义为准。 代码实践 somaxconnpython的一个不含accept()的服务端代码，这样可以让socket滞留在completed connection queue队列里面。 123456789101112import socketimport times = socket.socket(socket.AF_INET, socket.SOCK_STREAM)host = &quot;0.0.0.0&quot;port = 12345s.bind((host, port))BACKLOG = 2s.listen(BACKLOG)print(&apos;listening&apos;)time.sleep(3600) 查看下系统somaxconn的值：12[root@leanote ~]# sysctl -a | grep somaxconnnet.core.somaxconn = 128 启动进程，先不使用客户端进行连接，使用ss查看进程pid。 123[root@leanote ~]# ss -anpl | egrep &quot;10187|Recv-Q&quot;Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port tcp LISTEN 0 5 *:12345 *:* users:((&quot;python3&quot;,pid=10187,fd=3)) 这里涉及到Recv-Q和Send-Q两个字段，这两个字段的含义和前面state字段为何种状态密不可分，解释如下 Recv-Q Established: The count of bytes not copied by the user program connected to this socket.(套接字缓冲还没有被应用程序取走的字节数) Listening: Since Kernel 2.6.18 this column contains the current syn backlog. (当前syn backlog为backlog+1) Send-Q Established: The count of bytes not acknowledged by the remote host.(没有被远端确认的字节数) Listening: Since Kernel 2.6.18 this column contains the maximum size of the syn backlog. Send-Q 对应的值是5，这个值也就是代码中listen()中BACKLOG的值。 此时如果调整BACKLOG至256，重新启动进程，然后用ss查看信息： 123456789101112import socketimport times = socket.socket(socket.AF_INET, socket.SOCK_STREAM)host = &quot;0.0.0.0&quot;port = 12345s.bind((host, port))BACKLOG = 256s.listen(BACKLOG)print(&apos;listening&apos;)time.sleep(3600) 123[root@leanote ~]# ss -anp |egrep &quot;12345|Recv-Q&quot;Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port tcp LISTEN 0 128 *:12345 *:* users:((&quot;python3&quot;,pid=19593,fd=3)) Send-Q被系统somaxcon限制为128，调整系统somaxcon的值后，重启进程，然后ss继续观察 12[root@leanote ~]# sysctl net.core.somaxconn=65522net.core.somaxconn = 65522 123[root@leanote ~]# ss -anp |egrep &quot;12345|Recv-Q&quot;Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port tcp LISTEN 0 256 *:12345 *:* users:((&quot;python3&quot;,pid=19839,fd=3)) 变成了程序代码里定义的BACKLOG值了。 让客户端进行建联 客户端代码： 12345678910import socketimport timehost = &apos;122.152.220.151&apos;port = 12345sockets=[]while True: s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.connect((host, port)) sockets.append(s) time.sleep(10) 代码中BACKLOG修改为2 使用ss观察服务端 1234567891011[root@leanote ~]# ss -anp |egrep &quot;12345|Recv-Q&quot;Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port tcp LISTEN 3 2 *:12345 *:* users:((&quot;python3&quot;,pid=20361,fd=3))tcp SYN-RECV 0 0 10.105.31.91:12345 118.24.105.81:35986 tcp SYN-RECV 0 0 10.105.31.91:12345 118.24.105.81:36012 tcp SYN-RECV 0 0 10.105.31.91:12345 89.248.167.131:56380 tcp SYN-RECV 0 0 10.105.31.91:12345 118.24.105.81:35994 tcp SYN-RECV 0 0 10.105.31.91:12345 118.24.105.81:36002 tcp ESTAB 0 0 10.105.31.91:12345 118.24.105.81:35972 tcp ESTAB 0 0 10.105.31.91:12345 118.24.105.81:35952 tcp ESTAB 0 0 10.105.31.91:12345 118.24.105.81:35960 建联3个后(ESTAB),其他请求一直处于SYN-RECV状态。 Recv-Q为3，表示当前syn backlog为3 ,backlog+1的结果(2+1)。 当BACKLOG满的时候，抓包情况：123456789101112131415[root@leanote ~]# tcpdump -i any port 12345 -nnn &gt; 111[root@leanote ~]# cat 111 | grep 3718216:11:58.519076 IP 118.24.105.81.37182 &gt; 10.105.31.91.12345: Flags [S], seq 1450185841, win 29200, options [mss 1424,sackOK,TS val 3561765739 ecr 0,nop,wscale 7], length 016:11:58.519145 IP 10.105.31.91.12345 &gt; 118.24.105.81.37182: Flags [S.], seq 1044766216, ack 1450185842, win 28960, options [mss 1460,sackOK,TS val 3121876725 ecr 3561765739,nop,wscale 7], length 016:11:58.578420 IP 118.24.105.81.37182 &gt; 10.105.31.91.12345: Flags [.], ack 1, win 229, options [nop,nop,TS val 3561765798 ecr 3121876725], length 016:11:59.853632 IP 10.105.31.91.12345 &gt; 118.24.105.81.37182: Flags [S.], seq 1044766216, ack 1450185842, win 28960, options [mss 1460,sackOK,TS val 3121878060 ecr 3561765798,nop,wscale 7], length 016:11:59.912872 IP 118.24.105.81.37182 &gt; 10.105.31.91.12345: Flags [.], ack 1, win 229, options [nop,nop,TS val 3561767133 ecr 3121876725], length 016:12:02.053621 IP 10.105.31.91.12345 &gt; 118.24.105.81.37182: Flags [S.], seq 1044766216, ack 1450185842, win 28960, options [mss 1460,sackOK,TS val 3121880260 ecr 3561767133,nop,wscale 7], length 016:12:02.112871 IP 118.24.105.81.37182 &gt; 10.105.31.91.12345: Flags [.], ack 1, win 229, options [nop,nop,TS val 3561769333 ecr 3121876725], length 016:12:06.253625 IP 10.105.31.91.12345 &gt; 118.24.105.81.37182: Flags [S.], seq 1044766216, ack 1450185842, win 28960, options [mss 1460,sackOK,TS val 3121884460 ecr 3561769333,nop,wscale 7], length 016:12:06.312908 IP 118.24.105.81.37182 &gt; 10.105.31.91.12345: Flags [.], ack 1, win 229, options [nop,nop,TS val 3561773533 ecr 3121876725], length 016:12:14.253636 IP 10.105.31.91.12345 &gt; 118.24.105.81.37182: Flags [S.], seq 1044766216, ack 1450185842, win 28960, options [mss 1460,sackOK,TS val 3121892460 ecr 3561773533,nop,wscale 7], length 016:12:14.312821 IP 118.24.105.81.37182 &gt; 10.105.31.91.12345: Flags [.], ack 1, win 229, options [nop,nop,TS val 3561781533 ecr 3121876725], length 016:12:30.253631 IP 10.105.31.91.12345 &gt; 118.24.105.81.37182: Flags [S.], seq 1044766216, ack 1450185842, win 28960, options [mss 1460,sackOK,TS val 3121908460 ecr 3561781533,nop,wscale 7], length 016:12:30.312821 IP 118.24.105.81.37182 &gt; 10.105.31.91.12345: Flags [.], ack 1, win 229, options [nop,nop,TS val 3561797533 ecr 3121876725], length 0 对客户端一直发送syn+ack包。([S.] S表示syn，.表示ack)6次后，不再继续发送 虽然服务端ESTAB状态只有3个，但是对客户端而言，存在多个 1234567891011121314151617181920212223242526272829303132[root@VM_0_15_centos ~]# netstat -ant | grep 12345tcp 0 0 172.27.0.15:37326 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37410 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37312 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37242 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37232 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37360 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37266 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37442 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37458 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37468 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37214 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37392 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37282 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37292 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37182 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37174 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37222 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37370 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37400 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37430 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37206 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37418 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37342 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37352 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37252 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37384 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37334 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37274 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37450 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37300 122.152.220.151:12345 ESTABLISHEDtcp 0 0 172.27.0.15:37192 122.152.220.151:12345 ESTABLISHED 对于客户端而言，服务端发送了syn+ack已经算是三次握手成功了。 tcp_max_syn_backlogThe maximum number of queued connection requests which have still not received an acknowledgement from the connecting client. If this number is exceeded, the kernel will begin drop-ping requests.The maximum length of the queue for incomplete sockets can be set using /proc/sys/net/ipv4/tcp_max_syn_backlog. When syncookies are enabled there is no logical maximum length and this setting is ignored tcp_max_syn_backlog用来定义未建联的SYN-RECV状态队列长度。 当启用syncookies功能的时候，tcp_max_syn_backlog的功能将被忽视。 ###代码实践 tcp_max_syn_backlog 查看下系统tcp_max_syn_backlog的值：[root@leanote ~]# sysctl -a | grep tcp_max_syn_backlognet.ipv4.tcp_max_syn_backlog = 128 服务端ss查看1234567891011[root@leanote ~]# netstat -ant | grep 12345tcp 3 0 0.0.0.0:12345 0.0.0.0:* LISTEN tcp 0 0 10.105.31.91:12345 118.24.105.81:37926 SYN_RECV tcp 0 0 10.105.31.91:12345 118.24.105.81:37894 SYN_RECV tcp 0 0 10.105.31.91:12345 118.24.105.81:37944 SYN_RECV tcp 0 0 10.105.31.91:12345 118.24.105.81:37936 SYN_RECV tcp 0 0 10.105.31.91:12345 118.24.105.81:37908 SYN_RECV tcp 0 0 10.105.31.91:12345 118.24.105.81:37918 SYN_RECV tcp 0 0 10.105.31.91:12345 118.24.105.81:37874 ESTABLISHEDtcp 0 0 10.105.31.91:12345 118.24.105.81:37864 ESTABLISHEDtcp 0 0 10.105.31.91:12345 118.24.105.81:37882 ESTABLISHED 输出发现SYN_RECV状态状态很多，虽然连接处于SYN_RECV，一段时间后，自动删除，但是通过调整tcp_max_syn_backlog的值可以调整同一时间内SYN_RECV的数量。 调整成为2个：12[root@leanote ~]# sysctl net.ipv4.tcp_max_syn_backlog=2net.ipv4.tcp_max_syn_backlog = 2 因为当syncookies功能开启的时候，tcp_max_syn_backlog不会发挥作用，所以syncookies也得暂停：12[root@leanote ~]# sysctl net.ipv4.tcp_syncookies=0net.ipv4.tcp_syncookies = 0 客户端服务端重启，然后ss查看状态：12345678[root@leanote ~]# ss -ant | grep 12345LISTEN 3 2 *:12345 *:* SYN-RECV 0 0 10.105.31.91:12345 118.24.105.81:38456 SYN-RECV 0 0 10.105.31.91:12345 118.24.105.81:38470 SYN-RECV 0 0 10.105.31.91:12345 118.24.105.81:38398 ESTAB 0 0 10.105.31.91:12345 118.24.105.81:38280 ESTAB 0 0 10.105.31.91:12345 118.24.105.81:38264 ESTAB 0 0 10.105.31.91:12345 118.24.105.81:38272 这个syn_backlog设定的是2，但观察SYN-RECV最多出现3个。可能也是syn_backlog+1。待考证。 12345678910111213141516[root@leanote ~]# netstat -s | grep drop 20 dropped because of missing route 19 ICMP packets dropped because they were out-of-window 92307 SYNs to LISTEN sockets dropped [root@leanote ~]# dmesg | tail -n 10[3124021.575444] TCP: drop open request from 118.24.105.81/38910[3124025.583391] TCP: drop open request from 118.24.105.81/38910[3124033.599301] TCP: drop open request from 118.24.105.81/38910[3124049.647044] TCP: drop open request from 118.24.105.81/38910[3124111.900356] TCP: drop open request from 118.24.105.81/38996[3124112.902233] TCP: drop open request from 118.24.105.81/38996[3124114.908171] TCP: drop open request from 118.24.105.81/38996[3124118.916112] TCP: drop open request from 118.24.105.81/38996[3124126.924020] TCP: drop open request from 118.24.105.81/38996[3124142.955770] TCP: drop open request from 118.24.105.81/38996 服务器开始丢弃syn包，以及丢弃从客户端发送来的新连接。 总结 tcp_max_syn_backlog用来定义未建联的SYN-RECV状态队列长度。但当启用syncookies功能的时候失效。 somaxconn会限制listen()函数中BACKLOG的值。 somaxconn在高并发下需要调整，默认128绝逼不够用。 refer https://www.jianshu.com/p/30b861cac826https://www.jianshu.com/p/7fde92785056https://linux.die.net/man/2/listenhttp://www.agr.unideb.hu/~agocs/informatics/11_e_unix/unixhelp/unixhelp.ed.ac.uk/CGI/man-cgiaa65.html?tcp+7http://zake7749.github.io/2015/03/17/SocketProgramming/http://man7.org/linux/man-pages/man2/accept.2.htmlhttps://blog.csdn.net/tennysonsky/article/details/45621341]]></content>
      <tags>
        <tag>linux</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux平均负载]]></title>
    <url>%2F2019%2F02%2F05%2Flinux%E5%B9%B3%E5%9D%87%E8%B4%9F%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[linux平负载定义 单位时间内，处于运行或者准备运行(R)，以及不可中断睡眠进程(D)数量的平均值(指数平滑法)。 和cpu使用率没有直接关系。 负载上升，可能是cpu使用率过高，也可能是磁盘io问题。 平均负载算法其算法为指数平滑法，内核因为不可以直接做浮点运算，而选择定点运算的方式来计算指数平滑法。 指数平滑法公式： linux 2.6.18内核 loadt = loadt-1 α + n (1 – α)，[0 &lt; α &lt; 1] linux 3.12内核 loadt = loadt-1 α + n (1 – α) + z，[0 &lt; α &lt; 1] 3.12内核增加了修正值z。 loadt表示当前时刻一段时间内的平滑均值。loadt-1表示上一时间段的平滑均值。α Linux Kernel要计算的是前1min, 5min, 15min的Load 均值，α需要分别选取。Linux Kernel选取的是: e-5/(60m)5:表示5s，作分子。60:表示60s。m: 表示分钟，1, 5, 15。 60 m作为分母。把m带入到公式计算，分别能计算出0.920044415，0.983471454，0.994459848 参考文档: http://brytonlee.github.io/blog/2014/05/07/linux-kernel-load-average-calc/ multi-core vs multi-processor load关注机器有多少个processor 1234此公式包含超线程数。[root@leanote ~]# cat /proc/cpuinfo | grep &quot;processor&quot; | wc -l1[root@leanote ~]# core可以理解为核心数，也就是cpu核心总数，而processor理解为逻辑cpu个数，而非真实cpu个数，这个逻辑cpu个数等于top后按1查看到的结果。 linux查看cpu信息总核数 = 物理CPU个数 X 每颗物理CPU的核数总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数 查看物理CPU个数cat /proc/cpuinfo| grep “physical id”| sort| uniq| wc -l 查看每个物理CPU中core的个数(即核数)cat /proc/cpuinfo| grep “cpu cores”| uniq 查看逻辑CPU的个数cat /proc/cpuinfo| grep “processor”| wc -l refer http://brytonlee.github.io/blog/2014/05/07/linux-kernel-load-average-calc/]]></content>
      <tags>
        <tag>linux</tag>
        <tag>cpu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kill -9 不起作用]]></title>
    <url>%2F2019%2F02%2F02%2Fkill-9%E4%B8%8D%E8%B5%B7%E4%BD%9C%E7%94%A8%2F</url>
    <content type="text"><![CDATA[案例在公司压测，因为担心磁盘读写影响性能，所以磁盘通过nfs挂载。之后发现挂载内容无法进行读取，于是乎想重新挂载，umount命令下去，提示Device is busy，那就是铁定挂载目录或者文件被进程占用了，随之查询到了进程，打算用kill pid让进程暂停，但发现没有成功，随后用kill -9 pid强制暂停，但发现也没成功，进程pid一直存在，进程也未退出。 原因谷歌查询了下，得到了一个准确的回答。原文见refer。 kill不论发送任何信号，都是异步传递信号，内核传递信号给pid存在非常小的时间，但即便如此小的时间，也是需要进程腾出这么个时间点来接受，并处理，但如果进程当时处于阻止信号状态，那么发送过去的信号会被队列，等进程不在阻止信号后再传入，并且执行信号。 通常情况下，进程不会阻止信号，但是如果此时进程调用内核代码(系统调用)，而内核代码是可以阻止信号传入的。当中断系统调用会导致内核中某处形成错误的数据结构，或者内核一些不变量被违反的时候，内核代码会阻塞所有信号传入。所以，若出现bug或其他异常情况触发了无限期的系统调用阻塞，那么就无法传递kill发送的信号。 在系统调用中被阻塞的进程，一般称为不可中断进程，通过ps或者top，查看状态为D的进程，一般磁盘读写数据的时候是处于不可中断进程状态。 一个典型的例子就是nfs挂载的情况，当server没有响应的时候，往往会一直处于不可中断情况。 解决方法暂停server端和clinet端的nfs进程，重新挂载解决。 top ps查看不可中断进程1ps -eo pid,ppid,stat,pri,uid 进程状态常见标记符 R 表示进程正在Cpu的就绪队列中，正在运行或者正在等待运行。 D 是disk sleep缩写，也就是不可中断状态睡眠，一般表示进程正在和硬件交互，而交互过程不允许被其他进程或中断打断。 Z 僵尸进程，实际上进程已经结束，但是父进程没有回收他的资源，比如进程描述符，pid等。 S 是interruptible sleep缩写，表示可中断状态睡眠，表示进程因为等待某个事件而被挂起，当进程等到事件发生时，他会被唤醒进入R状态。 I 是idle缩写，也是空闲状态，用在不可中断睡眠的内核线程上。前面的D是表示硬件交互导致的不可中断，但对某些内核线程来说，他们有可能实际上并没有任何负载，这边用Idle为了区分这种情况。D状态进程会导致平均负载升高，I状态的进程却不会。 T 表示stopped状态，表示进程处于暂停状态(十字符病毒，一般都先对进程stop，然后排查问题)，发送SIGSTP就可以让进程暂停，再发送SIGCONT信号，则恢复运行。 t 表示跟踪状态。比如用gdb调试进程。 X 表示Dead，进程已经消亡，所以在ps或者top里面无法看到。 refer: https://cis.temple.edu/~ingargio/cis307/readings/signals.htmlhttps://unix.stackexchange.com/questions/5642/what-if-kill-9-does-not-workhttps://www.cnblogs.com/my_life/articles/5630903.html]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[setdefault方法传入函数]]></title>
    <url>%2F2019%2F02%2F01%2Fsetdefault%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[setdefault()方法myvalue = dict_a.setdefault(a,b) 从dict_a中获取a的值，如果没有，则新增一个value为b，key为a的键值对。 案例请求获取一个数值，如果字典中存在这个值，则从字典内获取，如果不存在，则从api函数调用。 于是用了setdefault()方法，代码大致如下: 12345dict_a = &#123;&#125;for i in xxxx: myvalue = dict_a.setdefault(a,func_api()) xxxxx xxx 因为func_api()函数会请求线上，调用接口。 但是实现的时候，却发现，每次对myvalue赋值的时候，都会调用线上api接口。 猜测setdefault的逻辑，即便能通过指定的key获取到value，其default行为还是被执行。 验证猜测同时也验证了字典get方法 123456789101112&gt;&gt;&gt; def b():... print(2)... return 1... &gt;&gt;&gt; a_dict = &#123;&#125;&gt;&gt;&gt; a_dict=&#123;&quot;a&quot;:1&#125;&gt;&gt;&gt; a_dict.setdefault(&quot;a&quot;,b())21&gt;&gt;&gt; a_dict.get(&quot;a&quot;,b())21 虽然a_dict字典已经存在”a”:1,但，依旧执行了b() 处理方法先进行get，若返回为None，则进行setdefault 12345groupid = groupid_templateid_dict.get(tmp_groupname)if groupid: passelse: groupid = groupid_templateid_dict.setdefault(tmp_groupname,zhg.get_customer_hostgroups(name=groupname,output_data=output_data)) 这样就避免了重复调用func的问题。 结论其实只要把函数作为另外一个函数的参数，那么当调用这个函数的的时候，被传入的函数也会调用。]]></content>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python防注入]]></title>
    <url>%2F2019%2F01%2F30%2FPython%E9%98%B2%E6%B3%A8%E5%85%A5%2F</url>
    <content type="text"><![CDATA[注入案例：12345678910111213141516import MySQLdbdb = MySQLdb.connect(host=&quot;localhost&quot;,user=&quot;&quot;,passwd=&quot;&quot;,db=&quot;&quot;)cur = db.cursor()platform = input(&apos;Enter language: &apos;)cur.execute(&quot;SELECT * FROM platforms WHERE language = &apos;%s&apos;;&quot; % platform)for row in cur.fetchall():print(row)db.close() 上述代码，让用户输入想查询的language，如果用户按套路，比如输入Ruby，则可以正常查询。 执行代码为：1SELECT * FROM platforms WHERE language = &apos;Ruby&apos;; 但如果搞事情输入Ruby’; DROP TABLE platforms;那么platforms表被删除。执行代码为：1SELECT * FROM platforms WHERE language = &apos;Ruby&apos;; DROP TABLE platforms;&apos;; 防止sql注入代码改写为如下:12345678910111213141516import MySQLdbdb = MySQLdb.connect(host=&quot;localhost&quot;,user=&quot;&quot;,passwd=&quot;&quot;,db=&quot;&quot;)cur = db.cursor()platform = raw_input(&apos;Enter language: &apos;)cur.execute(&quot;SELECT * FROM platforms WHERE language = %s;&quot;, (platform,))for row in cur.fetchall():print (row)db.close() 这边%s是占位符，和字符串format的方式不同，而且后面的元组前面也不需要%符号，即便是数字，也是用%s来占位。 防sql原因之所以能防sql是因为execute函数会对传入的args内容预处理。12345678910111213def mogrify(self, query, args=None): &quot;&quot;&quot; Returns the exact string that is sent to the database by calling the execute() method. This method follows the extension to the DB API 2.0 followed by Psycopg. &quot;&quot;&quot; conn = self._get_db() if PY2: # Use bytes on Python 2 always query = self._ensure_bytes(query, encoding=conn.encoding) if args is not None: query = query % self._escape_args(args, conn) execute后续调用一些函数，比如下面escape_string函数。(能力有限，前面几级调用不是非常看得懂。) 12345def escape_string(self, s): if (self.server_status &amp; SERVER_STATUS.SERVER_STATUS_NO_BACKSLASH_ESCAPES): return s.replace(&quot;&apos;&quot;, &quot;&apos;&apos;&quot;) return converters.escape_string(s) refer https://blog.sqreen.io/preventing-sql-injections-in-python/]]></content>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 只出现一次的数字]]></title>
    <url>%2F2019%2F01%2F28%2FLeetCode-%E5%8F%AA%E5%87%BA%E7%8E%B0%E4%B8%80%E6%AC%A1%E7%9A%84%E6%95%B0%E5%AD%97%2F</url>
    <content type="text"><![CDATA[需求给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。 说明你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？ 示例112输入: [2,2,1]输出: 1 示例212输入: [4,1,2,1,2]输出: 4 解题思路 使用异或的方式，非常巧妙，异或算法为相同为0，不同为1。 数字A异或数字B两次，则结果为A。 利用这个方法，可以找到非空数组里面只出现一次的那个元素。 0和数字B进行异或，得到的结果为数字B，基于这点，到最后所有元素异或剩下的结果就是只出现一次的那个元素。 解题代码1234567891011class Solution: def singleNumber(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: int &quot;&quot;&quot; a = 0 for num in nums: a = a ^ num print(a) return a]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 最后一个单词长度]]></title>
    <url>%2F2019%2F01%2F24%2FLeetCode-%E6%9C%80%E5%90%8E%E4%B8%80%E4%B8%AA%E5%8D%95%E8%AF%8D%E7%9A%84%E9%95%BF%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[需求给定一个仅包含大小写字母和空格 ‘ ‘ 的字符串，返回其最后一个单词的长度。 如果不存在最后一个单词，请返回 0 。 说明一个单词是指由字母组成，但不包含任何空格的字符串。 示例12输入: &quot;Hello World&quot;输出: 5 解题思路 两种情况，一种是为空，第二种是非空字符串。 字符串为空，则直接返回0，非空字符串，则返回最后一个单词。 python用split()方法，默认以空格，制表符等分割字符串，成为一个list。 解题代码123456789101112class Solution(object): def lengthOfLastWord(self, s): &quot;&quot;&quot; :type s: str :rtype: int &quot;&quot;&quot; slist = s.split() print(slist) if slist == []: return 0 return len(slist[-1]) refer: https://leetcode-cn.com/problems/length-of-last-word/submissions/]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 实现strStr()]]></title>
    <url>%2F2019%2F01%2F23%2FLeetCode-%E5%AE%9E%E7%8E%B0strStr%2F</url>
    <content type="text"><![CDATA[需求实现 strStr() 函数。 给定一个 haystack 字符串和一个 needle 字符串，在 haystack 字符串中找出 needle 字符串出现的第一个位置 (从0开始)。如果不存在，则返回 -1。 示例12输入: haystack = &quot;hello&quot;, needle = &quot;ll&quot;输出: 2 12输入: haystack = &quot;aaaaa&quot;, needle = &quot;bba&quot;输出: -1 说明当 needle 是空字符串时，我们应当返回什么值呢？这是一个在面试中很好的问题。 对于本题而言，当 needle 是空字符串时我们应当返回 0 。这与C语言的 strstr() 以及 Java的 indexOf() 定义相符。 解题思路python非常简单，直接使用find命令就可以查询到指定字符串第一次出现的position。 解题代码12345678class Solution(object): def strStr(self, haystack, needle): &quot;&quot;&quot; :type haystack: str :type needle: str :rtype: int &quot;&quot;&quot; return haystack.find(needle) refer https://leetcode-cn.com/problems/implement-strstr/]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[磁盘无法挂载]]></title>
    <url>%2F2019%2F01%2F18%2F%E7%A3%81%E7%9B%98%E6%97%A0%E6%B3%95%E6%8C%82%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[案例今天一机器的磁盘掉了，机房更换了硬盘。看了下前人都是写在/etc/fstab里面，个人不推荐写这里，写入/etc/rc.local更加好 然后修改了/etc/fstab，然后mount -a挂载，没报错，df -h没看到挂上去的盘，很奇怪。 查看了下message日志：12345Jan 18 14:55:55 SH-HDP1136 systemd: Unmounted /mnt/disk4.Jan 18 14:55:55 SH-HDP1136 systemd: Unit mnt-disk4.mount entered failed state.Jan 18 14:56:41 SH-HDP1136 kernel: XFS (sdd): Mounting V5 FilesystemJan 18 14:56:41 SH-HDP1136 kernel: XFS (sdd): Ending clean mountJan 18 14:56:41 SH-HDP1136 systemd: Unit mnt-disk4.mount is bound to inactive unit dev-disk-by\x2duuid-5aad6483\x2de21f\x2d498d\x2d9c8c\x2dfeff9fd5be76.device. Stopping, too. 最后一行谷歌查了下文档，第一篇文档说是用了重启大法。因为服务器比较重要，没考虑重启。 然后找到第二篇文档，说执行systemctl-reload，然后进行挂载。 尝试了下，的确成功了。 诡异的systemctl-reload但心里很纳闷，我修改个/etc/fstab和systemctl-reload有半毛钱关系，继续查了下谷歌，发现这是一个redhat7.4的bug。。。。。 Bug ID: 1566088 https://bugzilla.redhat.com/show_bug.cgi?id=1566088 refer: http://mamchenkov.net/wordpress/2017/11/09/systemd-strikes-again-unit-var-whatever-mount-is-bound-to-inactive-unit/https://bugzilla.redhat.com/show_bug.cgi?id=1566088]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[is和==比较区别]]></title>
    <url>%2F2019%2F01%2F17%2Fis%E5%92%8C%3D%3D%E6%AF%94%E8%BE%83%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[is** is比较的对象为内存地址 12345678&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; b = a[:]&gt;&gt;&gt; id(a)140379285741320&gt;&gt;&gt; id(b)140379285738696&gt;&gt;&gt; a is bFalse ==** ==比较的对象是值 12345678&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; b = a[:]&gt;&gt;&gt; id(a)140379285741320&gt;&gt;&gt; id(b)140379285738696&gt;&gt;&gt; a == bTrue 关于int类型的缓存123456789101112131415161718&gt;&gt;&gt; a = 1&gt;&gt;&gt; b = 1&gt;&gt;&gt; id(a)9322464&gt;&gt;&gt; id(b)9322464&gt;&gt;&gt; a is bTrue&gt;&gt;&gt; a = 999&gt;&gt;&gt; b = 999&gt;&gt;&gt; id(a)140379285517520&gt;&gt;&gt; id(b)140379285517584&gt;&gt;&gt; a is bFalse 上述当ab都等于1的时候，两者指向的内存地址一致，但当ab赋值了999后，两者指向的内存地址不一致。 产生的原因python对于int类型进行缓存，当int属于[-5, 256]范围的时候，会被缓存，倘若在这个区间进行赋值，则指向的内存地址都是一致的。 这个产生的原因比较复杂，倘若a和b都赋值在同一行，则两者is比较也是True，具体可以看refer。 https://stackoverflow.com/questions/15171695/whats-with-the-integer-cache-inside-python]]></content>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[是地址引用还是赋值操作]]></title>
    <url>%2F2019%2F01%2F17%2F%E6%98%AF%E5%9C%B0%E5%9D%80%E5%BC%95%E7%94%A8%E8%BF%98%E6%98%AF%E8%B5%8B%E5%80%BC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[基本类型凡是基本类型，都是赋值。 12345a = 1b = Nonec = True 复合类型若是复合类型，都是地址指向。 函数和类的赋值也是地址指向 12345a = [1,2,3]b = &#123;&apos;a&apos;:1, &apos;b&apos;:1&#125;c = 函数，类 验证方法直接用id()看地址引用，如果原始对象改变后，其id()和赋值对象的id()不再一致，则为赋值，反之则是引用。 验证基本类型：1234567891011&gt;&gt;&gt; a = 3&gt;&gt;&gt; b = a&gt;&gt;&gt; id(a)9413248&gt;&gt;&gt; id(b)9413248&gt;&gt;&gt; a = 4&gt;&gt;&gt; id(a)9413280&gt;&gt;&gt; id(b)9413248 给a第二次更变赋值为4后，b的id()和a的id()不同，所以是赋值 验证复合类型：12345678910111213&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; b = a&gt;&gt;&gt; b[1, 2, 3]&gt;&gt;&gt; id(a)140435242878376&gt;&gt;&gt; id(b)140435242878376&gt;&gt;&gt; a.append(1)&gt;&gt;&gt; id(a)140435242878376&gt;&gt;&gt; id(b)140435242878376 给a第二次更变赋值为4后，b的id()和a的id()相同，所以是地址引用。下面的类的例子也能看出是地址引用。 1234567891011121314151617class A(object): def test(self): passa = A()b = aprint(id(a))print(id(b))a.value = 1print(id(a))print(b.value)1402331338442401402331338442401402331338442401]]></content>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[带宽测试]]></title>
    <url>%2F2019%2F01%2F15%2F%E5%B8%A6%E5%AE%BD%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[场景当时是想测试单台服务器，流量到某带宽值，cpu，内存，磁盘io的表现。现在单说iperf和nc的简单使用。 iperf简单使用 server端启用iperf -s client端连接server端，默认端口是5001,iperf -c ${server_ip} ${port} server端：12345678[root@SCA-LX5700025 ~]# iperf -s------------------------------------------------------------Server listening on TCP port 5001TCP window size: 85.3 KByte (default)------------------------------------------------------------[ 4] local 10.8.199.17 port 5001 connected with 10.8.199.18 port 38008[ ID] Interval Transfer Bandwidth[ 4] 0.0-10.0 sec 1.13 GBytes 971 Mbits/sec client端：12345678[root@SCA-LX5700026 ~]# iperf -c 10.8.199.17 -p 5001------------------------------------------------------------Client connecting to 10.8.199.17, TCP port 5001TCP window size: 85.0 KByte (default)------------------------------------------------------------[ 3] local 10.8.199.18 port 38008 connected with 10.8.199.17 port 5001[ ID] Interval Transfer Bandwidth[ 3] 0.0-10.0 sec 1.13 GBytes 973 Mbits/sec 出来的结果直接是带宽，比如上面的是趋近于1000M带宽。 参数没有研究太多参数，更多参数可以-h查看。 -b 指定带宽12345678[root@SCA-LX5700026 ~]# iperf -c 10.8.199.17 -p 5001 -b 500M------------------------------------------------------------Client connecting to 10.8.199.17, TCP port 5001TCP window size: 85.0 KByte (default)------------------------------------------------------------[ 3] local 10.8.199.18 port 38010 connected with 10.8.199.17 port 5001[ ID] Interval Transfer Bandwidth[ 3] 0.0-10.0 sec 625 MBytes 524 Mbits/sec nc简单使用 server端启用nc -vvlnp ${server_port} &gt;/dev/null，或者-4指定只使用ipv4的方式。 client端连接dd if=/dev/zero bs=1M count=1K | nc ${server_ip} ${server_port}，命令测试的是1G文件的下载速度。 server端：123456[root@SCA-LX5700025 ~]# nc -vv4lnp 5001 &gt;/dev/nullNcat: Version 7.50 ( https://nmap.org/ncat )Ncat: Listening on 0.0.0.0:5001Ncat: Connection from 10.8.199.18.Ncat: Connection from 10.8.199.18:38410.NCAT DEBUG: Closing fd 4. client端：1234[root@SCA-LX5700026 ~]# dd if=/dev/zero bs=1M count=1K | nc 10.8.199.17 50011024+0 records in1024+0 records out1073741824 bytes (1.1 GB) copied, 8.7875 s, 122 MB/s refer: https://askubuntu.com/questions/7976/how-do-you-test-the-network-speed-between-two-boxes]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql字符集字符序]]></title>
    <url>%2F2019%2F01%2F10%2Fmysql%E5%AD%97%E7%AC%A6%E9%9B%86%E5%AD%97%E7%AC%A6%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[Emmmm….数据库默认配置，建库没指定字符集，然后你懂得，所有库，表，部分字段字符集都是latin1。 MariaDB version 10.1.36 数据库分字符集(character)和字符序(collation) character定义了字符以及字符的编码。 collation定义了字符的比较规则。 有四个地方涉及到字符集和字符序 服务器端(server level) 数据库(database level) 表(table level) char varchar text类型的字段(column level) 如果都未进行指定，采用何种character和collation，则默认情况为character=latin1, collation=latin1_swedish_ci 字符集 查看当前支持的字符集SHOW charsets，Default collation字段告知了，该字符集所用的默认字符序。 123456789101112mysql&gt; SHOW charset;+----------+-----------------------------+---------------------+--------+| Charset | Description | Default collation | Maxlen |+----------+-----------------------------+---------------------+--------+| big5 | Big5 Traditional Chinese | big5_chinese_ci | 2 || dec8 | DEC West European | dec8_swedish_ci | 1 || cp850 | DOS West European | cp850_general_ci | 1 || hp8 | HP West European | hp8_english_ci | 1 || koi8r | KOI8-R Relcom Russian | koi8r_general_ci | 1 |...... 查看server level当前的字符集SHOW VARIABLES LIKE &quot;character_set_server&quot;，查看server level当前的字符序SHOW VARIABLES LIKE &quot;collation_server&quot; 修改server level字符集的方法: 修改配置文件 编译的时候 set 全局变量命令。但这种情况重启会失效。 如果创建库，或者表，或者字段，或者配置文件my,cnf中只指定了字符集，则默认的字符序为该字符集所对应的默认字符序。 字符序 查看当前支持的字符序SHOW collation, Default字段存在Yes的，表示该字符集默认的default值。比如latin1默认的字符序为latin1_swedish_ci 1234567891011121314151617mysql&gt; SHOW collation;+--------------------------+----------+-----+---------+----------+---------+| Collation | Charset | Id | Default | Compiled | Sortlen |+--------------------------+----------+-----+---------+----------+---------+| big5_chinese_ci | big5 | 1 | Yes | Yes | 1 || big5_bin | big5 | 84 | | Yes | 1 || dec8_swedish_ci | dec8 | 3 | Yes | Yes | 1 || dec8_bin | dec8 | 69 | | Yes | 1 || cp850_general_ci | cp850 | 4 | Yes | Yes | 1 || cp850_bin | cp850 | 80 | | Yes | 1 || hp8_english_ci | hp8 | 6 | Yes | Yes | 1 || hp8_bin | hp8 | 72 | | Yes | 1 || koi8r_general_ci | koi8r | 7 | Yes | Yes | 1 || koi8r_bin | koi8r | 74 | | Yes | 1 || latin1_german1_ci | latin1 | 5 | | Yes | 1 || latin1_swedish_ci | latin1 | 8 | Yes | Yes | 1 || latin1_danish_ci | latin1 | 15 | | Yes | 1 | 如果创建库，或者表，或者字段，或者配置文件my,cnf中只指定了字符序，则默认的字符集为该字符序所对应的字符集。 字符序表示的含义 一般来说分为三段，也存在一段或者两段的情况，常见的三段如utf8mb4_general_ci,两段的如utf8mb4_bin(这类情况，其实只存在第一段和第三段，第二段不存在) 第一段代表字符集。 第二段代表语言(chinese,swedish),也有general这种通用的，或者unicode类型。 第三段代表是否敏感，是否为bin。 对于第三段的解释12345_ai Accent insensitive_as Accent sensitive_ci Case insensitive_cs case-sensitive_bin Binary Accent是否为sensitive表现为，如果为sensitive，则比较a和á是不同的，如果为insensitive则a和á比较为相同。 Case insensitive为大小写不敏感，case-sensitive为大小写敏感。 字符集和字符序的继承顺序 数据库服务，建库，建表，建字段，倘若其中有指定character和collation，则字段继承表，表继承库，库继承数据库服务。比如建库指定了字符集为utf8，那么该库下面的表如果不指定字符集，则表的字符集也为utf8，char、varchar、text的字段字符集也是utf8。 有个例外，如果修改了表， 那么该表下面的字段的字符集和字符序也会变成表的字符集和字符序。 修改查看字符集命令： 修改运行环境： 1234SET character_set_server = utf8mb4set character_set_connection = utf8mb4set character_set_database = utf8mb4set character_set_results = utf8mb4 修改库: 1234ALTER DATABASE dbname CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;验证语句 show create database dbname; 修改表: 12345671. dir varchar(255) -&gt; varchar(191) mysql5.6的版本需要修改。不保证所有版本都需要修改。ALTER TABLE dir_stats MODIFY dir VARCHAR(191);2. 修改字段类型utf8mb4alter table tablename convert to character set utf8mb4 collate utf8mb4_unicode_ci;验证语句SHOW FULL COLUMNS FROM dbname.tablename; refer: https://www.cnblogs.com/chyingp/p/mysql-character-set-collation.htmlhttps://mariadb.com/kb/zh-cn/setting-character-sets-and-collationshttps://dev.mysql.com/doc/refman/8.0/en/charset-database.htmlhttp://zarez.net/?p=719]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Promotions in Program C]]></title>
    <url>%2F2019%2F01%2F08%2FPromotions-in-Program-C%2F</url>
    <content type="text"><![CDATA[scanf()函数不会自行提升成double类型，printf()函数会自行提升成double类型。12345678910111213#include &lt;stdio.h&gt;void main(void) &#123; double num; printf(&quot;input a double type number: &quot;); scanf(&quot;%f&quot;, &amp;num); printf(&quot;the number is %f\n&quot;, num); printf(&quot;the number is %lf\n&quot;, num);&#125;input a double type number: 1the number is 0.000000the number is 0.000000 scanf()函数因为指向的是num的指针,所以不适用float promotions to double scanf()若使用double类型，必须写成”%lf”, 而printf()即便指定的是”%f”,也会自行提升成double类型。 1234567891011121314#include &lt;stdio.h&gt;void main(void) &#123; double num; printf(&quot;input a double type number: &quot;); scanf(&quot;%lf&quot;, &amp;num); printf(&quot;the number is %f\n&quot;, num); printf(&quot;the number is %lf\n&quot;, num);&#125;input a double type number: 1the number is 1.000000the number is 1.000000 integer-promotionsrefer: https://stackoverflow.com/questions/19952200/scanf-printf-double-variable-chttp://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf [6.5.2.2 page-71]https://www.geeksforgeeks.org/integer-promotions-in-c/]]></content>
      <tags>
        <tag>c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c语言基本数字类型]]></title>
    <url>%2F2019%2F01%2F06%2Fc%E8%AF%AD%E8%A8%80%E5%9F%BA%E6%9C%AC%E6%95%B0%E5%AD%97%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[基本数字类型关键字 int long short unsigned char float double signed _Bool (c99加入的bool类型) _Complex (c99加入的复数类型) _Imaginary (c99加入的虚数类型) 有符号整形有符号类型可用于表示正整数和负整数。 int 系统给定的基本整数类型，c语言规定int类型不小于16位。 short或short int 最大的shrot类型整数小于或等于最大的int类型整数。c语言规定short类型至少占16位。 long或long int 该类型可表示的整数大于或等于最大的int类型整数。c语言规定long类型至少占位32位。 long long或long long int 该类型可以表示的整数大于或等于最大的long类型整数。long long 类型至少占64位。 一般而言，long类型的占用内存比short类型大，int类型的宽度要和和long类型相同，要么和short类型相同。 无符号整形无符号整形只能用于表示零和正整数，因此无符号整形可以表示的正整数比有符号整形的大。在整形类型前面加上关键字unsigned表明该类型是无符号整形。单独的unsigned相当于unsigned int。 字符类型char类型实际上存储的是整数，而非字符。ASCII编码范围是0~127，所以只需要7位二进制数表示即可(这里不包含中文日文等特殊字符集)。char类型表示一个字符要占用1个字节内存，出于历史原因，一个字节通常是8位，但是如果要表示基本字符集，也可以是16位或更大。 char 字符类型的关键字，有些编译器使用有符号的char，而有些则使用无符号的char。在需要时，可以在char前面加上关键字signed或unsigned来指明，具体使用哪一种类型。 布尔类型布尔值表示true和false。c语言用1表示true，0表示false _Bool 布尔类型的关键字，c99加入。其类型为无符号int类型，所占用的个空间只要能存储0或者1即可。 实浮点类型(实数浮点类型)实浮点类型可以表示正浮点数和负浮点数。 float 系统基本浮点类型，可精确表示至少6位有效数字。 double 存储浮点数的范围更大，能表示比float类型更多的有效数字(至少15位)和更大的指数。 long long 存储浮点束的范围比double更大，能表示比double更多的有效数字和更大的指数。 复数和虚数浮点数虚数类型是可选的类型。复数的实部和虚部类型都基于实浮点类型来构成。 float _Complex double _Complex long double _Complex float _Imaginary double _Imaginary long double _Imaginary]]></content>
      <tags>
        <tag>c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[未配置中间证书CA引起的安卓端无法通过https建联加载图片案例]]></title>
    <url>%2F2019%2F01%2F06%2F%E6%9C%AA%E9%85%8D%E7%BD%AE%E4%B8%AD%E9%97%B4%E8%AF%81%E4%B9%A6CA%E5%BC%95%E8%B5%B7%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AF%E6%97%A0%E6%B3%95%E9%80%9A%E8%BF%87https%E5%BB%BA%E8%81%94%E5%8A%A0%E8%BD%BD%E5%9B%BE%E7%89%87%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[问题描述安卓同事称代码调试访问test-material.aaa.tv/xxx/xxxx.png等图片资源的时候报错，报错信息类似如下： 1javax.net.ssl.SSLHandshakeException: java.security.cert.CertPathValidatorException: Trust anchor for certification path not found. 问题分析查看了安卓的开放文档，出现该报错主要由一下三种情况发生： 颁发服务器证书的 CA 未知。 服务器证书不是由 CA 签署的，而是自签署。 服务器配置缺少中间 CA。 首先排除第一点和第二点，证书是购买的赛门铁克。 然后去ssllabs网站测试test-material.aaa.tv域名支持的https建联加密方式 起先怀疑是安卓可能使用了SSL3的加密方式进行https简练握手，后来确认安卓使用版本之后排除了该情况。 接着使用浏览器访问资源查看发现存在中间CA证书，但用域名检测网站的时候提示不含中间CA证书。于是乎又抓了一个安卓端可以显示的图片的域名来测试，在测试网站上也是属于不包含中间CA证书的情况。 两者的区别是，无法建联的域名是阿里云上的，能建联显示图片的域名是腾讯云上的。 当时很纳闷，后来查阅资料得知不同软件或者设备会有不同的行为，有些即便不存在中间CA也会帮忙代理查找。 安卓(其他苹果设备应该也是如此)自身会信任一些根证书，可能安卓去“解析”test-material.aaa.tv这个域名的时候得到的根证书，并不在信任证书里面，从而导致https建联失败。 于是发现安卓的确是存在信任一些列证书的情况： 然后来获取下test-material.aaa.tv的根证书情况，自然，在浏览器端获取到的可能是浏览器帮助代理请求获得的。得在服务器端用命令去查看，命令如下： 1openssl s_client -connect test-material.aaa.tv:443 -servername test-material.aaa.tv -connect 检测的域名，后面跟随ssl端口号-servername 指定SNI(Server Name Indication)，因为可能存在多个域名对应一张证书的情况，比如买的证书是一级域名和二级域名都可以使用这种情况，那么需要指定具体的域名。 SNI (Server Name Indication)是用来改善服务器与客户端 SSL (Secure Socket Layer)和 TLS (Transport Layer Security) 的一个扩展。主要解决一台服务器只能使用一个证书(一个域名)的缺点，随着服务器对虚拟主机的支持，一个服务器上可以为多个域名提供服务，因此SNI必须得到支持才能满足需求。 上图已经修复问题，修复之前只有条目0，不包含条目1。 红框信息： 起始证书是C=CN/L=xxxxx(后面一大串)，然后C=CN/L=xxxxx(后面一大串)这个证书又是由GeoTrust Inc./CN=GeoTrust SSL CA - G3颁发。 修复问题之前只有条目0,没有条目1，然后在安卓信任证书列表里面查不到关于信任GeoTrust Inc./CN=GeoTrust SSL CA - G3这个证书的条目。所以建联无法通过了。 GeoTrust SSL CA - G3又是由Geo Trust Inc./CN=Geo Trust Global CA颁发。 修复问题之后可以在安卓端信任列表里面查到存在Geo Trust Global CA证书条目，所以建联成功了。 问题解决方法：中间证书CA没配置导致，上阿里云后台，查看该域名对应的证书，发现的确只有本机CA证书，没有配置中间证书CA，重新配置上后，问题解决，安卓端建联正常。 refer: https://developer.android.google.cn/training/articles/security-ssl.html#MissingCahttp://blog.csdn.net/makenothing/article/details/53292335 证书检测地址: https://www.ssllabs.com/ssltest/analyze.html 安卓文档对于缺失中间证书的描述:12345678有趣的是，在大多数桌面浏览器中访问此服务器不会引发完全未知的 CA 或自签署服务器证书所引发的类似错误。这是因为大多数桌面浏览器都会将可信的中间 CA 缓存一段时间。当浏览器从某个网站访问和了解中间 CA 后，下次它就不需要将中间 CA 添加在证书链中。有些网站会专门为提供资源的辅助网络服务器这样做。例如，他们可能让具有完整证书链的服务器提供主 HTML 页面，让不包含 CA 的服务器提供图像、CSS 或 JavaScript 等资源，以节省带宽。遗憾的是，这些服务器有时候可能会提供您正在尝试从 Android 应用调用的网络服务，这一点让人难以接受。可以通过两种方法解决此问题：配置服务器以便在服务器链中添加中间 CA。大多数 CA 都可以提供有关如何为所有常用网络服务器执行此操作的文档。如果您需要网站至少通过 Android 4.2 使用默认 Android 浏览器，那么这是唯一的方法。或者，像对待其他任何未知 CA 一样对待中间 CA，并创建一个 TrustManager 以直接信任它，如前面的两部分中所述。 查看证书到期时间：openssl s_client -connect www.icoinbay.com:443 -servername www.icoinbay.com 2&gt;/dev/null |openssl x509 -noout -dates]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bash fork: retry: Resource temporarily unavailable]]></title>
    <url>%2F2019%2F01%2F02%2Fbash-fork-retry-Resource-temporarily-unavailable%2F</url>
    <content type="text"><![CDATA[修改ulimit无法解决fork不出子进程的问题现场没有保留，大抵经过如下：朋友的一台系统为Ubuntu的机器，上面启动了一个进程，该进程会fork出子进程，但是当root用户所有的进程数到一万多后就无法继续fork了，输入命令开始报错bash fork: retry: Resource temporarily unavailable 排查经过： 起先我以为是ulimit的配置没修改，或者不够大，但使用ulimit -u看了下，65535，足够大了。 感觉虽然ulimit调整了，但是执行中的进程limit并没有到达65535，于是乎，去/proc/pid/limit查看了，发现max process也是65535。 那么不成是内存，cpu之类的(其实想想也不太可能，内存小也不会报fork错误)，看了发现完全够用。 这下懵圈了 bash fork: retry: Resource temporarily unavailable 这个报错绝逼是某个参数的配置配小了。 由于是Ubuntu的系统，所以和平常用的centos还是有区别的。选择谷歌了，查来查去，一堆人都说是修改ulimit参数。 最后是找到了这篇文章： https://askubuntu.com/questions/845380/bash-fork-retry-resource-temporarily-unavailable 里面让修改的地方是一个名为pid.max的文件，和我机器路径稍微有点出入，我的路径是在/sys/fs/cgroup/pids/user.slice/user-0.slice/pid.max 这个数值只有10813，所以ps -eLf | wc -l到一万七八就上不去了。 这个文件的数量改动后立马生效，不需要重启 重启机器后，这个值又会还原成10813，看来Ubuntu系统默认pid.max的值为10813(当时我没注意Ubuntu具体是哪个版本。。。。)，这个值如何产生的目前还不太清楚。 centos7在centos7上 获取当前进程数：cat /sys/fs/cgroup/pids/pids.current 类似使用ps -ef | wc -l 获取当前线程数和进程数总和：wc -l /sys/fs/cgroup/pids/tasks 类似使用ps -eLf | wc -l centos7上也是可以实现pid.max：只需要在/sys/fs/cgroup/pids/下创建以为目录，则该目录中就会自动创建pid.max：1234[root@leanote test]# pwd/sys/fs/cgroup/pids/test[root@leanote test]# lscgroup.clone_children cgroup.event_control cgroup.procs notify_on_release pids.current pids.max tasks 对当前shell交互进程限制 1234567891011[root@leanote test]# lscgroup.clone_children cgroup.event_control cgroup.procs notify_on_release pids.current pids.max tasks[root@leanote test]# cat cgroup.procs [root@leanote test]# echo $$14514[root@leanote test]# echo 14514 &gt; cgroup.procs [root@leanote test]# echo 1 &gt; pids.max -bash: fork: retry: No child processes-bash: fork: Resource temporarily unavailable-bash: fork: retry: No child processes-bash: fork: retry: No child processes 给pid.max输入1后，直接就出-bash: fork: retry: No child processes报错了。 pid.max只会对cgroup.procs中存在的进程进行pid.max限制。 当进程消失后,cgroup.procs中的进程号也会自动消失。 在上一级不存在pid.max是因为对整个系统没必要做限制。Ubuntu系统上/sys/fs/cgroup/pids/user.slice/user-0.slice/pid.max这个其实是对用户编号为0的用户进行了pid.max的限制。 refer: 知乎上看到有个小伙伴也遇到这个问题了 https://zhuanlan.zhihu.com/p/29192624 fork的文档 http://man7.org/linux/man-pages/man2/fork.2.html cgroup介绍 https://segmentfault.com/a/1190000007241437https://mccxj.github.io/blog/20171230_os-thread-limit.html cgroup 进程数限制 https://segmentfault.com/a/1190000007468509]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sort函数中key的理解]]></title>
    <url>%2F2018%2F12%2F29%2Fsort%E5%87%BD%E6%95%B0%E4%B8%ADkey%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[sort()函数12345Help on method_descriptor:sort(...) L.sort(key=None, reverse=False) -&gt; None -- stable sort *IN PLACE*(END) python3中已经取消了sort()函数中cmp参数 python中sort()函数用来排序，其中有个key的参数，十分神奇。 我对key参数的理解是：这个key是构造了一个全新的对象，对这些全新的对象进行比较排序，然后再根据结果，对原先的对象进行排序。 字典value排序:比如很常用的，对一个字典进行value排序：123456d = &#123;1: &apos;c&apos;, 2:&apos;d&apos;, 3: &apos;b&apos;, 4: &apos;a&apos;&#125;def sort_value(x): return x[1]print(sorted(d.items(), key=sort_value)) d.items得到dict_items([(1, ‘c’), (2, ‘d’), (3, ‘b’), (4, ‘a’)])，其挨个传入到key对应的sort_value函数中，返回索引为1的值，也就是value的值，然后对这个新对象进行排序，最终以新对象排序的结果来输出d.items()的排序。 将sort_value函数写成lambda则：1print(sorted(d.items(), key=lambda x :x[1])) 字符串内容重新排序:对字符串”hUangYisan6749”重新排序，要求: 数字在最前面，偶数在奇数前面。 字符串在数字后面，大写字母在小写字母后面。 思路： 字符串挨个拆出来。 构造一个元组，能够符合上述需求，然后排序的。元组的排序是从首个元素逐一排序的，碰到首元素一样，则比第二个元素 先确定一个通用的元组，总共是四种类型，奇数偶数，大写小写。例：偶数，奇数，大写，小写(1,0,0,0)，比如这样就表示该字符为偶数。 由于默认sorted排序是从小到大，所以根据需求，得写成小写，大写，奇数，偶数的方式(或者加上reverse=True) 123456789def custom_order(x): if x.islower(): return 1,0,0,0,x if x.isupper(): return 0,1,0,0,x if x.isdigit() and int(x) % 2 == 0: return 0,0,1,0,x else: return 0,0,0,1,x 当对比相同的时候，会索引+1比较，所以return不能漏掉x，因为当前面四位全部相等的时候，要比较x。 那么代码可以写成：1234567891011121314mystring = &quot;hUangYisan6749&quot;def custom_order(x): if x.islower(): return 1,0,0,0,x if x.isupper(): return 0,1,0,0,x if x.isdigit() and int(x) % 2 == 0: return 0,0,1,0,x else: return 0,0,0,1,xprint(&quot;&quot;.join(sorted(mystring,key=custom_order)))7946UYaaghinns refer: http://python.jobbole.com/85025/]]></content>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[split函数]]></title>
    <url>%2F2018%2F12%2F29%2Fsplit%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[一道领扣的题给定一个仅包含大小写字母和空格 ‘ ‘ 的字符串，返回其最后一个单词的长度。如果不存在最后一个单词，请返回 0 。说明：一个单词是指由字母组成，但不包含任何空格的字符串。 示例:12输入: &quot;Hello World&quot;输出: 5 写出的其中一种答案是：123456789101112class Solution(object): def lengthOfLastWord(self, s): &quot;&quot;&quot; :type s: str :rtype: int &quot;&quot;&quot; slist = s.split() print(slist) if slist == []: return 0 return len(slist[-1]) split(“ “) 和 split()起先我认为split(“ “)和split()的作用是一样的，都是以空格进行分割。以至于一开始做上面领扣的题一直都有问题。 然后手工验证了下两者的情况： split(“ “)的情况 12&gt;&gt;&gt; &quot; a &quot;.split(&quot; &quot;)[&apos;&apos;, &apos;a&apos;, &apos;&apos;, &apos;&apos;, &apos;&apos;] split()的情况 12&gt;&gt;&gt; &quot; a &quot;.split()[&apos;a&apos;] 查了下split()的用法 123S.split([sep [,maxsplit]]) -&gt; list of stringsReturn a list of the words in the string S, using sep as the delimiter string. If maxsplit is given, at most maxsplit splits are done. If sep is not specified or is None, any whitespace string is a separator and empty strings are removed from the result. 也就是说，如果sep不填写，那么split()执行两个行为： 以任何whitespace字符串作为分隔符。 除所有的empty string。 empty string就是not xxx返回结果为False的字符串,包括””。 refer: https://leetcode-cn.com/problems/length-of-last-word/help(str.split)]]></content>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7网卡改名]]></title>
    <url>%2F2018%2F12%2F27%2Fcentos7%E7%BD%91%E5%8D%A1%E6%94%B9%E5%90%8D%2F</url>
    <content type="text"><![CDATA[客户瞎搞，两张网卡，说是看着名称不爽，自行修改了网卡名，为bond0和bond1，bond1能启动，而bond0无法启动。我这边接手擦屁股。 先说udev服务，然后再看问题产生的原因。 system-udevd进程在centos6中为udevd进程：12[root@VM_31_91_centos6 ~]# ps -ef | grep udevroot 470 1 0 01:17 ? 00:00:00 /sbin/udevd -d 在centos7中为system-udevd进程12[root@VM_31_91_centos7 ~]# ps -ef | grep udevroot 460 1 0 10月09 ? 00:00:00 /usr/lib/systemd/systemd-udevd udev的作用是：man udevreceives device uevents directly from the kernel whenever a device is added or removed from the system, or it changes its state.当有设备从系统插入或者拔出，或者改变了状态的时候，内核会直接收到设备uevents。 udev rules文件存在位置： system rules directory: /usr/lib/udev/rules.d volatile runtime directory: /run/udev/rules.d local administration directory: /etc/udev/rules.d udev读取文件规则： 读取这些目录下以.rules为后缀的文件。 文件先后顺序和其所在目录无关，和文件的名称顺序有关。 若不同目录存在相同的文件，则根据目录名称来排优先级顺序。/etc&gt;/run&gt;/usr udev进行网卡重命名 https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/networking_guide/sec-understanding_the_device_renaming_procedure?tdsourcetag=s_pctim_aiomsg 优先查询的是/usr/lib/udev/rules.d/60-net.rules配置文件。如果发现包含 HWADDR 条目的 ifcfg 文件与某个接口的 MAC 地址匹配，它会将该接口重命名为 ifcfg 文件中由 DEVICE 指令给出的名称。 问题产生的原因当时发现/usr/lib/udev/rules.d/60-net.rules文件内已经存在了bond1的配置，而bond0的配置写到了/etc/udev/rules.d/70-persistent-net.rules里面，由于60的优先级高于70，所以bond0网卡一直起不来。 其实centos7已经不用70-persistent-net.rules这个文件了，在centos6中，删除了70-persistent-net.rules文件，他会通过/lib/udev/write_net_rules文件来生成，但centos7已经不存在该文件了，centos7是使用/lib/udev/rename_device文件来生成/usr/lib/udev/rules.d/60-net.rules。 合理修改centos7网卡名称流程首先修改当前网卡名称 123/sbin/ip link set eth1 down/sbin/ip link set eth1 name eth123/sbin/ip link set eth123 up 然后在/usr/lib/udev/rules.d/60-net.rules中加入配置策略ACTION==”add”, SUBSYSTEM==”net”, DRIVERS==”?*”, ATTR{address}==”00:50:56:8e:3f:a7”, NAME=”eth123” 最后修改ifcfg-xxx里面的NAME和DEVICE字段值为eth123。 重启网卡即可。 refer: https://www.freedesktop.org/software/systemd/man/udev.html#https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/networking_guide/sec-understanding_the_device_renaming_procedure?tdsourcetag=s_pctim_aiomsghttps://unix.stackexchange.com/questions/205010/centos-7-rename-network-interface-without-rebooting]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从无法加载JAVA_HOME说起]]></title>
    <url>%2F2018%2F12%2F25%2F%E4%BB%8E%E6%97%A0%E6%B3%95%E5%8A%A0%E8%BD%BDJAVA-HOME%E8%AF%B4%E8%B5%B7%2F</url>
    <content type="text"><![CDATA[这几天在做jenkins cicd的事儿，用sudo的方式启动tomcat，直接报出无法找到JAVA_HOME。当时挺纳闷的，因为我在/etc/profile里面是添加了JAVA_HOME。123456789[root@ccc bin]# sudo ./catalina.sh startNeither the JAVA_HOME nor the JRE_HOME environment variable is definedAt least one of these environment variable is needed to run this program[root@ccc bin]# tail -n 5 /etc/profileexport JAVA_HOME=/tool/jdk1.8.0_144export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$PATH:$JAVA_HOME/binexport JAVA_HOME CLASSPATH PATH 如此如此，出现了两个疑问。 为什么/etc/profile的内容无法被加载？ 在/etc/profile里面写入jdk环境变量是否合适？ 为什么/etc/profile的内容无法被加载？先说下一个概念，linux的用户交互模式。在linux中用户交互模式可以分为两类： Interactive Shell Non-Interactive Shell Interactive Shell 顾名思义，就是登陆用户可以和shell进行交互的，比如你用xshell上一台服务器，出现的terminal就是属于Interactive Shell方式。Non-Interactive Shell 非交互的模式，比如用crontab的方式执行一个shell脚本。 那么问题就来了，这两种模式的环境变量从哪里去获取呢？ Interactive Shell登录情况 123456789101112execute /etc/profileIF ~/.bash_profile exists THEN execute ~/.bash_profileELSE IF ~/.bash_login exist THEN execute ~/.bash_login ELSE IF ~/.profile exist THEN execute ~/.profile END IF END IFEND IF 一目了然，入口为/etc/profile文件。其中在.bash_profile里面还判断是否存在~/.bashrc，如果存在则加载~/.bashrc。 12if [ -f ~/.bashrc ]; then . ~/.bashrc 还没完，在执行~/.bashrc的时候里面继续判断是否存在/etc/bashrc，如果存在则执行/etc/bashrc。 123if [ -f /etc/bashrc ]; then . /etc/bashrcfi 顺带一说，当用户退出Interactive Shell的时候，执行~/.bash_logout内容。所以可以在退出的时候定义一些行为。 123IF ~/.bash_logout exists THEN execute ~/.bash_logoutEND IF 总结下Interactive Shell的顺序： /etc/profile ~/.bash_profile ~/.bashrc /etc/bashrc ~/.bash_login ~/.profile ~/.bash_logout (当且仅当退出Interactive Shell的时候执行) Non-Interactive Shell的情况 123IF ~/.bashrc exists THEN execute ~/.bashrcEND IF 直接去执行的~/.bashrc，该文件也会判断是否存在/etc/bashrc，存在则执行/etc/bashrc。 总结下Non-Interactive Shell的顺序： ~/.bashrc /etc/bashrc 看似原因好像是因为sudo ./catalina.sh start进入了Non-Interactive Shell，从而没加载/etc/profile，其实并不是这样的。sudo在这边搞出了幺蛾子？ sudo做了啥？命令输入visudo，有那么一节内容： 1234567891011121314# Preserving HOME has security implications since many programs# use it when searching for configuration files. Note that HOME# is already set when the the env_reset option is enabled, so# this option is only effective for configurations where either# env_reset is disabled or HOME is present in the env_keep list.#Defaults always_set_homeDefaults env_resetDefaults env_keep = &quot;COLORS DISPLAY HOSTNAME HISTSIZE INPUTRC KDEDIR LS_COLORS&quot;Defaults env_keep += &quot;MAIL PS1 PS2 QTDIR USERNAME LANG LC_ADDRESS LC_CTYPE&quot;Defaults env_keep += &quot;LC_COLLATE LC_IDENTIFICATION LC_MEASUREMENT LC_MESSAGES&quot;Defaults env_keep += &quot;LC_MONETARY LC_NAME LC_NUMERIC LC_PAPER LC_TELEPHONE&quot;Defaults env_keep += &quot;LC_TIME LC_ALL LANGUAGE LINGUAS _XKB_CHARSET XAUTHORITY&quot; 其行为会将env reset，但是会保留部分环境变量。这一行为导致了sudo ./catalina.sh start无法寻找到jdk变量。 比较差劲的解决方法：man一下sudo，有个-E的参数，能保留之前的环境变量，但是不推荐这样做，因为有安全隐患： 123-E The -E (preserve environment) option indicates to the security policy that the user wishes to preserve their existing environment variables. The security policy may return an error if the -E option is specified and the user does not have permission to preserve the environment. 1234567[root@ccc bin]# sudo -E ./catalina.sh startUsing CATALINA_BASE: /opt/mixcdn-tomcatUsing CATALINA_HOME: /opt/mixcdn-tomcatUsing CATALINA_TMPDIR: /opt/mixcdn-tomcat/tempUsing JRE_HOME: /tool/jdk1.8.0_144Using CLASSPATH: /opt/mixcdn-tomcat/bin/bootstrap.jar:/opt/mixcdn-tomcat/bin/tomcat-juli.jarTomcat started. 好的解决方法在下面： 在/etc/profile里面写入jdk环境变量是否合适？针对部署tomcat的jdk环境，很多文档，包括我自己，之前也是从别人那边拿来的部署jdk文档，将jdk环境变量写入/etc/profile，等文件中，这个观念基本上贯穿了我整个运维生涯。 其实官方给出了写法，在catalina.sh里面: 12345678910111213141516171819202122232425262728# Control Script for the CATALINA Server## Environment Variable Prerequisites## Do not set the variables in this script. Instead put them into a script# setenv.sh in CATALINA_BASE/bin to keep your customizations separate.## CATALINA_HOME May point at your Catalina &quot;build&quot; directory.## CATALINA_BASE (Optional) Base directory for resolving dynamic portions# of a Catalina installation. If not present, resolves to........# Ensure that any user defined CLASSPATH variables are not used on startup,# but allow them to be specified in setenv.sh, in rare case when it is needed.CLASSPATH=if [ -r &quot;$CATALINA_BASE/bin/setenv.sh&quot; ]; then . &quot;$CATALINA_BASE/bin/setenv.sh&quot;elif [ -r &quot;$CATALINA_HOME/bin/setenv.sh&quot; ]; then . &quot;$CATALINA_HOME/bin/setenv.sh&quot;fi........ 就是在tomcat/bin目录下面，写入一个setenv.sh文件里面写入需要的环境变量，当运行catalina.sh启动脚本的时候，其会进行执行该setenv.sh文件，当前我的版本是1.8，非特殊情况其已经不需要写入CLASSPATH。(据说jdk1.5之后就不需要写入CLASSPATH了。) 123[root@ccc bin]# cat setenv.shexport JAVA_HOME=/tool/jdk1.8.0_144export PATH=$PATH:$JAVA_HOME/bin 多看官方文档，多看服务自带脚本还是非常有必要的。 Refer: https://www.thegeekstuff.com/2008/10/execution-sequence-for-bash_profile-bashrc-bash_login-profile-and-bash_logout/https://bencane.com/2013/09/16/understanding-a-little-more-about-etcprofile-and-etcbashrc/https://stackoverflow.com/questions/8633461/how-to-keep-environment-variables-when-using-sudohttps://segmentfault.com/q/1010000011528636/a-1020000011538128 下次写sudo su两个命令。]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git clean/rm/reset/revert/checkout用法和区别]]></title>
    <url>%2F2018%2F12%2F22%2Fgit-clean-rm-reset-revert-checkout%E7%94%A8%E6%B3%95%E5%92%8C%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[git的工作区和暂存区先说下这两个概念：工作区，就是你git仓库的目录，你进行修改文件的区域。暂存区，git从库里面有个.git的隐藏目录，里面”有一块”，可以理解为暂存区。 工作区和缓存区如何联系起来？通过提交代码行为的步骤流程来解读: 修改代码文件 git add 修改后的代码文件 此刻的行为将该代码文件从工作区添加到了暂存区 git commit -m &#39;commit 内容&#39; 此刻的行为把暂存区的内容提交到了本地分支上 最后的git push操作只是一个将本地分支推送到远端的行为，所以先不考虑进去，只考前面三点。 查看工作区和暂存区常用的命令为git status 一般常见的是如下三种情况： 在工作区新建了文件或目录，但还未将这些文件或目录git add提交到暂存区。这些文件或目录被标记为untracked files。 123456789101112huangyisan:~/Desktop/github/test $ touch foo barhuangyisan:~/Desktop/github/test $ lsbar foohuangyisan:~/Desktop/github/test $ git statusOn branch masterUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) bar foonothing added to commit but untracked files present (use &quot;git add&quot; to track) 对修改后的文件进行了git add操作，将这些文件提交到了暂存区，但未执行git commit -m &#39;xxx&#39;，未提交到本地分支。此时文件属于Changes to be committed状态 123456789101112huangyisan:~/Desktop/github/test $ git add foohuangyisan:~/Desktop/github/test $ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: fooUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) bar 对已经git add操作，但未提交到本地分支的文件，继续进行了修改，修改完后未进行git add，此时文件属于Changes not staged for commit状态 123456789101112131415161718huangyisan:~/Desktop/github/test $ echo &apos;new line&apos; &gt;&gt; foohuangyisan:~/Desktop/github/test $ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: fooChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: fooUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) bar 已经commit到本地分支的文件，且该文件在工作区没被修改之前，其不会在git status中出现。 git checkout – file两种情况 若被checkout的文件在暂存区，但工作区修改了，也就是上面的第三种情况，此时执行该命令，被checkout的文件变成和暂存区一样的状态和内容。12345678910111213141516171819202122232425262728293031huangyisan:~/Desktop/github/test $ echo &apos;first line&apos; &gt; foohuangyisan:~/Desktop/github/test $ git add foohuangyisan:~/Desktop/github/test $ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: foohuangyisan:~/Desktop/github/test $ cat foofirst linehuangyisan:~/Desktop/github/test $ echo &apos;new line&apos; &gt;&gt; foohuangyisan:~/Desktop/github/test $ cat foofirst linenew linehuangyisan:~/Desktop/github/test $ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: fooChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: foohuangyisan:~/Desktop/github/test $ git checkout -- foohuangyisan:~/Desktop/github/test $ cat foofirst line 将foo文件写入’first line’内容后，用git add foo，提交到了暂存区，未commit情况下，再写入新内容’new line’,若想还原到暂存区状态，则使用命令git checkout -- foo 被修改文件不在暂存区，此时使用git checkout -- file命令，则该文件和当前版本仓库中原先的文件一致。123456789101112huangyisan:~/Desktop/github/test $ git statusOn branch masternothing to commit, working tree cleanhuangyisan:~/Desktop/github/test $ cat foofirst linehuangyisan:~/Desktop/github/test $ echo &apos;new line&apos; &gt;&gt; foohuangyisan:~/Desktop/github/test $ cat foofirst linenew linehuangyisan:~/Desktop/github/test $ git checkout -- foohuangyisan:~/Desktop/github/test $ cat foofirst line 干净的工作区，修改了foo文件，然后进行checkout操作之后，foo文件还原成了仓库中该文件原先的状态和内容。 git cleangit clean 的对象为untracked files，也就是在工作区新建，但还未执行git add命令提交到暂存区的文件或目录。1234567891011121314151617181920212223huangyisan:~/Desktop/github/test $ lsbar foohuangyisan:~/Desktop/github/test $ touch new1 new2huangyisan:~/Desktop/github/test $ mkdir &#123;tmp1,tmp2&#125;huangyisan:~/Desktop/github/test $ lsbar foo new1 new2 tmp1 tmp2huangyisan:~/Desktop/github/test $ git clean -nWould remove new1Would remove new2huangyisan:~/Desktop/github/test $ git clean -f new1Removing new1huangyisan:~/Desktop/github/test $ git clean -df tmp1Removing tmp1/huangyisan:~/Desktop/github/test $ lsbar foo new2 tmp2huangyisan:~/Desktop/github/test $ git clean -fRemoving new2huangyisan:~/Desktop/github/test $ lsbar foo tmp2huangyisan:~/Desktop/github/test $ git clean -dfRemoving tmp2/huangyisan:~/Desktop/github/test $ lsbar foo git clean -n，干跑模式，可以列出哪些文件会被清除，但不会列出哪些目录会被清除。git clean -f，若指定文件，则该文件被清除，若不指定文件，则所有未被提交到暂存区的文件都被清除。git clean -df，若指定目录，则该目录被清除，若不指定目录，则所有未被提交到暂存区的目录都被清除。 git rmgit rm等价于rm xxx &amp;&amp; git add .。如果一个文件是被rm删除，则可以使用git checkout -- file将文件还原回来，而如果是用git rm删除，则该文件不可以被git checkout -- file。当然，如果是rm文件，然后git add操作，也是不能被git checkout -- file还原回来的。123456789101112131415huangyisan:~/Desktop/github/test $ lsbar foohuangyisan:~/Desktop/github/test $ rm fooremove foo? yhuangyisan:~/Desktop/github/test $ lsbarhuangyisan:~/Desktop/github/test $ git checkout foohuangyisan:~/Desktop/github/test $ lsbar foohuangyisan:~/Desktop/github/test $ git rm foorm &apos;foo&apos;huangyisan:~/Desktop/github/test $ git checkout fooerror: pathspec &apos;foo&apos; did not match any file(s) known to git.huangyisan:~/Desktop/github/test $ lsbar foo文件起先被rm删除，并未提交到暂存区，所以是可以被checkout还原，后来执行了git rm，所以当使用checkout还原的时候就报错了。 git reset三种模式 –mixed 默认方式，将暂存区内容清空，回退到工作区，并且保留工作区的修改内容。 1234567891011121314151617181920212223242526272829huangyisan:~/Desktop/github/test $ cat foofirst linehuangyisan:~/Desktop/github/test $ echo &apos;new line&apos; &gt;&gt; foohuangyisan:~/Desktop/github/test $ git add foohuangyisan:~/Desktop/github/test $ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: foohuangyisan:~/Desktop/github/test $ cat foofirst linenew linehuangyisan:~/Desktop/github/test $ git reset HEADUnstaged changes after reset:M foohuangyisan:~/Desktop/github/test $ cat foofirst linenew linehuangyisan:~/Desktop/github/test $ git statusOn branch masterChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: foono changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 暂存区被清空，工作区的更变被保留下来，foo文件存在new line这行内容。 –soft 暂存区内容，工作区内容都被保留，HEAD指向指定的commit号，该commit号原先的文件若有变动，则直接被add到暂存区。 123456789101112131415161718192021222324252627282930313233343536373839huangyisan:~/Desktop/github/test $ lsfoohuangyisan:~/Desktop/github/test $ cat foohuangyisan:~/Desktop/github/test $ echo &apos;new line&apos; &gt; foohuangyisan:~/Desktop/github/test $ git add foohuangyisan:~/Desktop/github/test $ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: foohuangyisan:~/Desktop/github/test $ git log --onelinee5ca64a (HEAD -&gt; master) 10ba0aa5 1ebaa828 1a2f32c5 18f89d40 updatebe60bed 1bb51c34 .df8f824 update4dbd952 update9e683fb 179dfad8 13e58cef add 194e5bf4 remove02aadbb okhuangyisan:~/Desktop/github/test $ git reset --soft 8f89d40huangyisan:~/Desktop/github/test $ lsfoohuangyisan:~/Desktop/github/test $ cat foonew linehuangyisan:~/Desktop/github/test $ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) deleted: bar new file: foo 将foo的改动add到暂存区后，使用git reset --soft 8f89d40，8f89d40这个commit号原先是存在bar这个文件，且foo文件不存在，因为reset之前的内容和之后的比较出现了差异，则这些差异被add到了新的暂存区中。 –hard HEAD重置到指定commit号，且清空暂存区，工作区的内容和该commit号版本仓库的内容一致。 123456huangyisan:~/Desktop/github/test $ git reset --hard HEADHEAD is now at 14d3892 1huangyisan:~/Desktop/github/test $ lsfoohuangyisan:~/Desktop/github/test $ cat foofirst line 暂存区被清空，工作区内容成了当前commit号版本仓库的内容，也就是没修改之前的内容，foo文件不存在new line行。但若工作区存在Untracked files，则这些Untracked files会携带进入到指定的commit号版本仓库的工作区中，所以要恢复到和某个commit号完全一致，还需要git clean -f清空Untracked files。 git reset会将HEAD指向的分支指向reset对应的commit，而git checkout是HEAD直接指向对应的commit。 git revert仅将某个commit号提交分支的内容撤销，且将此次撤销作为一个新的提交。 12345678910111213141516171819huangyisan:~/Desktop/github/test $ git log --oneline145af31 (HEAD -&gt; master) add newedf54e3 add fooc11842d add bar5f4b280 remove allhuangyisan:~/Desktop/github/test $ lsbar foo new new1huangyisan:~/Desktop/github/test $ git revert c11842d[master 19e736c] Revert &quot;add bar&quot; 1 file changed, 0 insertions(+), 0 deletions(-) delete mode 100644 barhuangyisan:~/Desktop/github/test $ lsfoo new new1huangyisan:~/Desktop/github/test $ git log --oneline19e736c (HEAD -&gt; master) Revert &quot;add bar&quot;145af31 add newedf54e3 add fooc11842d add bar5f4b280 remove all c11842d是将bar文件提交到了分支，当执行git revert c11842d,则撤销了提交bar文件到分支，所以执行完后，bar文件不见了，但foo文件依旧存在，所以revert只影响了被撤销的commit的变更内容，而且看git log，多了一个新的commit提交号19e736c。]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[getchar()存储类型]]></title>
    <url>%2F2018%2F12%2F20%2Fgetchar-%E5%AD%98%E5%82%A8%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[getchar()返回类型声明为int类型getchar()函数从文本流读入下一个输入字符，并且作为结果返回。 一个读取字符，并且打印的程序，当读取end of file(EOF)的时候结束。123456789101112#include &lt;stdio.h&gt;int main (void)&#123; int c; c = getchar(); while (c != EOF) &#123; putchar(c); c = getchar(); &#125; return 0;&#125; 起先没搞明白为什么对c的声明是int类型，而不是char类型。 后来查阅资料得知，char类型的声明，会根据不同的编译器，或者不同的架构平台，可能成为unsigned char或者是signed char类型。 如果是unsigned char类型，占8位，一个字节，其范围为0000 0000 ~ 1111 1111，即0 ~ 255，那么无法存储EOF这个结束符，EOF可以理解为数值-1(C89, C99, C11并没有给EOF定义一个具体的值，只是说EOF是一个负值常量)。 而当被作为signed char类型，虽然其取值范围为-128 ~ +127，虽然能够存储EOF这个结束符，看似正常，但在linux的环境，会混淆char 255和EOF，导致输入数据的截断。 在linux平台运行以下程序 1234567891011#include &lt;stdio.h&gt;int main(void)&#123; char c; printf(&quot;Enter characters : &quot;); while((c= getchar()) != EOF)&#123; putchar(c); &#125; return 0;&#125; 输出结果可以发现\0377后面部分没有被打印。 12[root@VM_31_91_centos ~]# gcc test.c &amp;&amp; echo -e &apos;Hello world\0377And some more&apos; | ./a.outEnter characters : Hello world[root@VM_31_91_centos ~]# getchar()和putchar()初始返回的值都为int类型。对于getchar()函数返回值的声明使用int类型 打印出EOF的值123456789101112131415#include &lt;stdio.h&gt;int main (void)&#123; int c; c = getchar(); while (c == EOF) &#123; printf(&quot;this is the value of EOF:%d&quot;,c); c = getchar(); break; &#125; return 0;&#125; 执行程序，按CTRL+D发送EOF，查看得到的数值为-1。 refer https://stackoverflow.com/questions/18013167/why-must-the-variable-used-to-hold-getchars-return-value-be-declared-as-inthttps://stackoverflow.com/questions/35356322/difference-between-int-and-char-in-getchar-fgetc-and-putchar-fputchttps://stackoverflow.com/questions/7119470/int-c-getcharThe C Programming Language - By Kernighan and Ritchie]]></content>
      <tags>
        <tag>c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[新式类的C3 MRO理解]]></title>
    <url>%2F2018%2F12%2F20%2F%E6%96%B0%E5%BC%8F%E7%B1%BB%E7%9A%84C3-MRO%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[新式类python2.3以及之后的版本遵循的原则：C3 MRO 其遵循的原则为：一个类同时继承的类中，如果没有共同父类，则往最左的类的父类查询；如果存在共同父类，则从左到右查询。 自省方法__mro__ 存在共同父类的情况123456789class D(object): passclass E(object): passclass F(object): passclass B(D, E): passclass C(D, F): passclass A(B, C): passprint(A.__mro__)(&lt;class &apos;__main__.A&apos;&gt;, &lt;class &apos;__main__.B&apos;&gt;, &lt;class &apos;__main__.C&apos;&gt;, &lt;class &apos;__main__.D&apos;&gt;, &lt;class &apos;__main__.E&apos;&gt;, &lt;class &apos;__main__.F&apos;&gt;, &lt;class &apos;object&apos;&gt;) 顺序解释:这边需要注意的是B和C有相同的父类，所以B查询后直接查询的C。 12345678910111213查询关系D --&gt; D,objectE --&gt; E,objectF --&gt; F,objectB --&gt; B, D, E, ...., objectC --&gt; C, D, F, ...., objectA --&gt; A. B, C, ...., object 将B和C带入后得到 --&gt; A, (B, D, E, ..., object), (C,D,F, ..., object) B和C存在共同的父类，D，所以B和C是同一级别，查询顺序是A, B, C, 然后D, --&gt; A, B, C, D (E, ..., object), (F, ..., object) --&gt; A, B, C, D, E, F, object 不存在共同父类的情况123456789101112class g(object): passclass f(object): passclass h(object): passclass i(object): passclass e(object): passclass d(h,i): passclass b(d,e): passclass c(f,g): passclass a(b,c): passprint(a.__mro__)(&lt;class &apos;__main__.a&apos;&gt;, &lt;class &apos;__main__.b&apos;&gt;, &lt;class &apos;__main__.d&apos;&gt;, &lt;class &apos;__main__.h&apos;&gt;, &lt;class &apos;__main__.i&apos;&gt;, &lt;class &apos;__main__.e&apos;&gt;, &lt;class &apos;__main__.c&apos;&gt;, &lt;class &apos;__main__.f&apos;&gt;, &lt;class &apos;__main__.g&apos;&gt;, &lt;class &apos;object&apos;&gt;) 顺序解释：因为b和c不存在相同的父类，所以查询b查不到后直接查询b的父类。 1234567891011121314151617查询关系：g --&gt; g, objectf --&gt; f, objecth --&gt; h, objecti --&gt; i, objecte --&gt; e, objectb --&gt; b, d, e, ..., objectc --&gt; c, f, g, ..., objectd --&gt; d, h, i, ..., objecta --&gt; a, b, c, ..., object 将B和C带入后得到 --&gt; a, (b, d, e, ..., object), (c, f, g, ..., object) 将b带入后得到 --&gt; a, (b, (d, h, i, ..., object), e, ..., object), (c, f, g, ..., object) b和c没有共同的父类，所以直接查询了d，d后，查询他的继承，h，因为h最顶了，所以开始依次返回，查询其平级的i，然后折回到b中右边的e,然后再次返回到a中右边的c，然后查询c中的f,发现到顶了，则查询其平级的g，然后依次退出，发现直接查询完了全部，则查询object。]]></content>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[True or False]]></title>
    <url>%2F2018%2F12%2F18%2FTrue-or-False%2F</url>
    <content type="text"><![CDATA[链式比较先来看一段代码: 12&gt;&gt;&gt; 2 in [1,0] == FalseFalse 起先我认为输出的结果是True，因为 2 in [1,0] 为False，接着False == False 返回的是True。 后来发现，这个其实是链式比较(chained comparisons)，这种比较法，常见的为类似1&lt;2&lt;3这种，能立马反应过来，其实质为 1&lt;2 and 2&lt;3。所以2 in [1,0] == False的本质其实为(2 in [1,0]) and ([1,0] == False)，很显然，前面的返回为False，后面的返回也为False，False and False的结果为False，所以最终得到的结果为False。 如下比较符号进行组合，都为链式比较“&lt;” | “&gt;” | “==” | “&gt;=” | “&lt;=” | “&lt;&gt;” | “!=” | “is” [“not”] | [“not”] “in” https://docs.python.org/2/reference/expressions.html#comparisons 空字符串代码如下： 12&gt;&gt;&gt; &quot;&quot; in &quot;abc&quot;True 空字符串始终被视为任何其他字符串的子字符串，所以其返回为True。字符串的比较等价于find()方法，x in y 等价于y.find(x) != -1。当find()执行结果为-1的时候，表示x不是y的子字符串，反之，则x为y的子字符串。空字符串的执行结果如下: 12&gt;&gt;&gt; &quot;abc&quot;.find(&apos;&apos;) != -1True https://docs.python.org/3/reference/expressions.html#membership-test-operations]]></content>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
</search>
